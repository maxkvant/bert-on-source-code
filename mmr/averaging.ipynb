{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "import csv\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import mmr.ds_loading\n",
    "import mmr.vectorization\n",
    "import cubert_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(x):\n",
    "    return x.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('/home/maxkvant/data/mmr/')\n",
    "\n",
    "test_classes_vecs_path = data_root / 'mmr_vecs_np'\n",
    "test_methods_vecs_path = data_root / 'mmr_vecs_wm'\n",
    "test_ds = mmr.ds_loading.MMRDataset(data_root / 'MoveMethodDataset', test_methods_vecs_path, test_classes_vecs_path, \n",
    "                                    vectorizer, vectorizer, True, True, precalculated=True)\n",
    "\n",
    "train_classes_vecs_path = data_root / 'mmr_tr_dsv'\n",
    "train_methods_vecs_path = data_root / 'mmr_tr_dsvwm_v2'\n",
    "train_ds = mmr.ds_loading.MMRDataset(data_root / 'mmr_tr_ds', train_methods_vecs_path, train_classes_vecs_path, \n",
    "                                     vectorizer, vectorizer, True, True, precalculated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actor-platform',\n",
       " 'atlas',\n",
       " 'buck',\n",
       " 'crate',\n",
       " 'deeplearning4j',\n",
       " 'drools',\n",
       " 'hbase',\n",
       " 'hive',\n",
       " 'jenkins',\n",
       " 'jstorm',\n",
       " 'pinpoint',\n",
       " 'pmd'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_tr = {i[0] for i in train_ds}\n",
    "c_te = {i[0] for i in test_ds}\n",
    "tr_exclude_projects = c_tr & c_te\n",
    "tr_exclude_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_exclude_projects = {'actor-platform', 'atlas', 'bazel', 'buck', 'crate', 'deeplearning4j', 'drools', 'hbase', 'hive', \n",
    "#                        'jenkins', 'jstorm', 'pinpoint', 'pmd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_train, proj_val = train_test_split(list(c_tr - tr_exclude_projects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_to_xy(ds, val_projects, exclude_projects = {}):\n",
    "    x_train, x_val, y_train, y_val = [], [], [], []\n",
    "    mn_train, mn_val = [], []\n",
    "    for project, mn, _, mv, cv, tgt in ds:\n",
    "        vec = np.concatenate((mv, cv))\n",
    "        if project in val_projects:\n",
    "            x_val.append(vec)\n",
    "            y_val.append(tgt)\n",
    "            mn_val.append(mn)\n",
    "        elif project not in exclude_projects:\n",
    "            x_train.append(vec)\n",
    "            y_train.append(tgt)\n",
    "            mn_train.append(mn)\n",
    "    return np.array(x_train), np.array(x_val), np.int64(y_train), np.int64(y_val), mn_train, mn_val\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val, mn_train, mn_val = ds_to_xy(train_ds, proj_val, tr_exclude_projects)\n",
    "x_test, _, y_test, _, mn_test, _ = ds_to_xy(test_ds, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.771722625274169, 0.753852142887309)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(C=10)\n",
    "svm_clf.fit(x_train, y_train)\n",
    "f1_score(y_val, svm_clf.predict(x_val)), roc_auc_score(y_val, svm_clf.predict(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.046785\n",
      "0:\tlearn: 0.6555173\ttest: 0.6762403\tbest: 0.6762403 (0)\ttotal: 1.55s\tremaining: 25m 51s\n",
      "1:\tlearn: 0.6267027\ttest: 0.6600211\tbest: 0.6600211 (1)\ttotal: 3.04s\tremaining: 25m 17s\n",
      "2:\tlearn: 0.5991910\ttest: 0.6421295\tbest: 0.6421295 (2)\ttotal: 4.47s\tremaining: 24m 47s\n",
      "3:\tlearn: 0.5728015\ttest: 0.6326780\tbest: 0.6326780 (3)\ttotal: 5.91s\tremaining: 24m 31s\n",
      "4:\tlearn: 0.5489978\ttest: 0.6169663\tbest: 0.6169663 (4)\ttotal: 7.39s\tremaining: 24m 30s\n",
      "5:\tlearn: 0.5296132\ttest: 0.6078033\tbest: 0.6078033 (5)\ttotal: 8.82s\tremaining: 24m 21s\n",
      "6:\tlearn: 0.5107164\ttest: 0.5923723\tbest: 0.5923723 (6)\ttotal: 10.2s\tremaining: 24m 13s\n",
      "7:\tlearn: 0.4968553\ttest: 0.5831999\tbest: 0.5831999 (7)\ttotal: 11.7s\tremaining: 24m 9s\n",
      "8:\tlearn: 0.4801428\ttest: 0.5762454\tbest: 0.5762454 (8)\ttotal: 13.2s\tremaining: 24m 9s\n",
      "9:\tlearn: 0.4641208\ttest: 0.5683839\tbest: 0.5683839 (9)\ttotal: 14.6s\tremaining: 24m 7s\n",
      "10:\tlearn: 0.4509662\ttest: 0.5581918\tbest: 0.5581918 (10)\ttotal: 16.1s\tremaining: 24m 5s\n",
      "11:\tlearn: 0.4343731\ttest: 0.5522962\tbest: 0.5522962 (11)\ttotal: 17.5s\tremaining: 24m 3s\n",
      "12:\tlearn: 0.4220604\ttest: 0.5441435\tbest: 0.5441435 (12)\ttotal: 19s\tremaining: 23m 59s\n",
      "13:\tlearn: 0.4091339\ttest: 0.5383500\tbest: 0.5383500 (13)\ttotal: 20.9s\tremaining: 24m 28s\n",
      "14:\tlearn: 0.3988636\ttest: 0.5348206\tbest: 0.5348206 (14)\ttotal: 22.4s\tremaining: 24m 29s\n",
      "15:\tlearn: 0.3883018\ttest: 0.5291492\tbest: 0.5291492 (15)\ttotal: 23.8s\tremaining: 24m 26s\n",
      "16:\tlearn: 0.3783216\ttest: 0.5265673\tbest: 0.5265673 (16)\ttotal: 25.3s\tremaining: 24m 20s\n",
      "17:\tlearn: 0.3692316\ttest: 0.5224217\tbest: 0.5224217 (17)\ttotal: 26.7s\tremaining: 24m 14s\n",
      "18:\tlearn: 0.3605546\ttest: 0.5190594\tbest: 0.5190594 (18)\ttotal: 28.1s\tremaining: 24m 9s\n",
      "19:\tlearn: 0.3531126\ttest: 0.5144690\tbest: 0.5144690 (19)\ttotal: 29.5s\tremaining: 24m 4s\n",
      "20:\tlearn: 0.3445721\ttest: 0.5120187\tbest: 0.5120187 (20)\ttotal: 30.9s\tremaining: 23m 59s\n",
      "21:\tlearn: 0.3371883\ttest: 0.5116122\tbest: 0.5116122 (21)\ttotal: 32.3s\tremaining: 23m 55s\n",
      "22:\tlearn: 0.3314808\ttest: 0.5077196\tbest: 0.5077196 (22)\ttotal: 33.7s\tremaining: 23m 52s\n",
      "23:\tlearn: 0.3240403\ttest: 0.5066527\tbest: 0.5066527 (23)\ttotal: 35.1s\tremaining: 23m 48s\n",
      "24:\tlearn: 0.3183535\ttest: 0.5047152\tbest: 0.5047152 (24)\ttotal: 36.6s\tremaining: 23m 47s\n",
      "25:\tlearn: 0.3131960\ttest: 0.5030572\tbest: 0.5030572 (25)\ttotal: 38.1s\tremaining: 23m 45s\n",
      "26:\tlearn: 0.3084265\ttest: 0.4996689\tbest: 0.4996689 (26)\ttotal: 39.5s\tremaining: 23m 43s\n",
      "27:\tlearn: 0.3037482\ttest: 0.4969432\tbest: 0.4969432 (27)\ttotal: 40.9s\tremaining: 23m 39s\n",
      "28:\tlearn: 0.2980753\ttest: 0.4926869\tbest: 0.4926869 (28)\ttotal: 42.3s\tremaining: 23m 37s\n",
      "29:\tlearn: 0.2929537\ttest: 0.4921008\tbest: 0.4921008 (29)\ttotal: 43.8s\tremaining: 23m 36s\n",
      "30:\tlearn: 0.2870772\ttest: 0.4890537\tbest: 0.4890537 (30)\ttotal: 45.2s\tremaining: 23m 34s\n",
      "31:\tlearn: 0.2819025\ttest: 0.4881367\tbest: 0.4881367 (31)\ttotal: 46.7s\tremaining: 23m 31s\n",
      "32:\tlearn: 0.2772955\ttest: 0.4883820\tbest: 0.4881367 (31)\ttotal: 48.1s\tremaining: 23m 28s\n",
      "33:\tlearn: 0.2735865\ttest: 0.4854851\tbest: 0.4854851 (33)\ttotal: 49.5s\tremaining: 23m 25s\n",
      "34:\tlearn: 0.2694114\ttest: 0.4850408\tbest: 0.4850408 (34)\ttotal: 50.9s\tremaining: 23m 22s\n",
      "35:\tlearn: 0.2654339\ttest: 0.4868240\tbest: 0.4850408 (34)\ttotal: 52.3s\tremaining: 23m 19s\n",
      "36:\tlearn: 0.2620452\ttest: 0.4866661\tbest: 0.4850408 (34)\ttotal: 53.7s\tremaining: 23m 17s\n",
      "37:\tlearn: 0.2594162\ttest: 0.4850419\tbest: 0.4850408 (34)\ttotal: 55.2s\tremaining: 23m 16s\n",
      "38:\tlearn: 0.2563963\ttest: 0.4846437\tbest: 0.4846437 (38)\ttotal: 56.6s\tremaining: 23m 14s\n",
      "39:\tlearn: 0.2534565\ttest: 0.4828226\tbest: 0.4828226 (39)\ttotal: 58s\tremaining: 23m 11s\n",
      "40:\tlearn: 0.2499178\ttest: 0.4816170\tbest: 0.4816170 (40)\ttotal: 59.4s\tremaining: 23m 9s\n",
      "41:\tlearn: 0.2469229\ttest: 0.4775044\tbest: 0.4775044 (41)\ttotal: 1m\tremaining: 23m 8s\n",
      "42:\tlearn: 0.2445595\ttest: 0.4770179\tbest: 0.4770179 (42)\ttotal: 1m 2s\tremaining: 23m 6s\n",
      "43:\tlearn: 0.2418670\ttest: 0.4756547\tbest: 0.4756547 (43)\ttotal: 1m 3s\tremaining: 23m 4s\n",
      "44:\tlearn: 0.2396638\ttest: 0.4737716\tbest: 0.4737716 (44)\ttotal: 1m 5s\tremaining: 23m 1s\n",
      "45:\tlearn: 0.2371383\ttest: 0.4737496\tbest: 0.4737496 (45)\ttotal: 1m 6s\tremaining: 22m 59s\n",
      "46:\tlearn: 0.2341580\ttest: 0.4742695\tbest: 0.4737496 (45)\ttotal: 1m 7s\tremaining: 22m 58s\n",
      "47:\tlearn: 0.2318467\ttest: 0.4732697\tbest: 0.4732697 (47)\ttotal: 1m 9s\tremaining: 22m 56s\n",
      "48:\tlearn: 0.2292673\ttest: 0.4702826\tbest: 0.4702826 (48)\ttotal: 1m 10s\tremaining: 22m 54s\n",
      "49:\tlearn: 0.2266193\ttest: 0.4707425\tbest: 0.4702826 (48)\ttotal: 1m 12s\tremaining: 22m 52s\n",
      "50:\tlearn: 0.2235824\ttest: 0.4675593\tbest: 0.4675593 (50)\ttotal: 1m 13s\tremaining: 22m 51s\n",
      "51:\tlearn: 0.2206583\ttest: 0.4654645\tbest: 0.4654645 (51)\ttotal: 1m 15s\tremaining: 22m 49s\n",
      "52:\tlearn: 0.2186776\ttest: 0.4649198\tbest: 0.4649198 (52)\ttotal: 1m 16s\tremaining: 22m 48s\n",
      "53:\tlearn: 0.2160005\ttest: 0.4643860\tbest: 0.4643860 (53)\ttotal: 1m 18s\tremaining: 22m 46s\n",
      "54:\tlearn: 0.2131734\ttest: 0.4634054\tbest: 0.4634054 (54)\ttotal: 1m 19s\tremaining: 22m 45s\n",
      "55:\tlearn: 0.2113843\ttest: 0.4621428\tbest: 0.4621428 (55)\ttotal: 1m 20s\tremaining: 22m 43s\n",
      "56:\tlearn: 0.2088895\ttest: 0.4629952\tbest: 0.4621428 (55)\ttotal: 1m 22s\tremaining: 22m 42s\n",
      "57:\tlearn: 0.2060771\ttest: 0.4608670\tbest: 0.4608670 (57)\ttotal: 1m 23s\tremaining: 22m 40s\n",
      "58:\tlearn: 0.2030524\ttest: 0.4602779\tbest: 0.4602779 (58)\ttotal: 1m 25s\tremaining: 22m 39s\n",
      "59:\tlearn: 0.2002728\ttest: 0.4607688\tbest: 0.4602779 (58)\ttotal: 1m 26s\tremaining: 22m 37s\n",
      "60:\tlearn: 0.1978672\ttest: 0.4589558\tbest: 0.4589558 (60)\ttotal: 1m 28s\tremaining: 22m 36s\n",
      "61:\tlearn: 0.1963202\ttest: 0.4584929\tbest: 0.4584929 (61)\ttotal: 1m 29s\tremaining: 22m 34s\n",
      "62:\tlearn: 0.1948687\ttest: 0.4581576\tbest: 0.4581576 (62)\ttotal: 1m 30s\tremaining: 22m 32s\n",
      "63:\tlearn: 0.1924999\ttest: 0.4572765\tbest: 0.4572765 (63)\ttotal: 1m 32s\tremaining: 22m 30s\n",
      "64:\tlearn: 0.1913769\ttest: 0.4561110\tbest: 0.4561110 (64)\ttotal: 1m 33s\tremaining: 22m 28s\n",
      "65:\tlearn: 0.1892506\ttest: 0.4562792\tbest: 0.4561110 (64)\ttotal: 1m 35s\tremaining: 22m 26s\n",
      "66:\tlearn: 0.1876850\ttest: 0.4558100\tbest: 0.4558100 (66)\ttotal: 1m 36s\tremaining: 22m 25s\n",
      "67:\tlearn: 0.1860745\ttest: 0.4553986\tbest: 0.4553986 (67)\ttotal: 1m 38s\tremaining: 22m 23s\n",
      "68:\tlearn: 0.1847458\ttest: 0.4560671\tbest: 0.4553986 (67)\ttotal: 1m 39s\tremaining: 22m 22s\n",
      "69:\tlearn: 0.1828984\ttest: 0.4550305\tbest: 0.4550305 (69)\ttotal: 1m 41s\tremaining: 22m 22s\n",
      "70:\tlearn: 0.1811717\ttest: 0.4546146\tbest: 0.4546146 (70)\ttotal: 1m 42s\tremaining: 22m 22s\n",
      "71:\tlearn: 0.1797666\ttest: 0.4547643\tbest: 0.4546146 (70)\ttotal: 1m 44s\tremaining: 22m 22s\n",
      "72:\tlearn: 0.1785211\ttest: 0.4543875\tbest: 0.4543875 (72)\ttotal: 1m 45s\tremaining: 22m 22s\n",
      "73:\tlearn: 0.1773531\ttest: 0.4540897\tbest: 0.4540897 (73)\ttotal: 1m 47s\tremaining: 22m 22s\n",
      "74:\tlearn: 0.1758560\ttest: 0.4525432\tbest: 0.4525432 (74)\ttotal: 1m 48s\tremaining: 22m 22s\n",
      "75:\tlearn: 0.1740477\ttest: 0.4530134\tbest: 0.4525432 (74)\ttotal: 1m 50s\tremaining: 22m 22s\n",
      "76:\tlearn: 0.1727263\ttest: 0.4532187\tbest: 0.4525432 (74)\ttotal: 1m 52s\tremaining: 22m 23s\n",
      "77:\tlearn: 0.1712527\ttest: 0.4525262\tbest: 0.4525262 (77)\ttotal: 1m 53s\tremaining: 22m 23s\n",
      "78:\tlearn: 0.1695302\ttest: 0.4512101\tbest: 0.4512101 (78)\ttotal: 1m 55s\tremaining: 22m 23s\n",
      "79:\tlearn: 0.1685459\ttest: 0.4509603\tbest: 0.4509603 (79)\ttotal: 1m 56s\tremaining: 22m 23s\n",
      "80:\tlearn: 0.1674098\ttest: 0.4503515\tbest: 0.4503515 (80)\ttotal: 1m 58s\tremaining: 22m 23s\n",
      "81:\tlearn: 0.1661863\ttest: 0.4495034\tbest: 0.4495034 (81)\ttotal: 1m 59s\tremaining: 22m 23s\n",
      "82:\tlearn: 0.1646685\ttest: 0.4483405\tbest: 0.4483405 (82)\ttotal: 2m 1s\tremaining: 22m 24s\n",
      "83:\tlearn: 0.1637117\ttest: 0.4489124\tbest: 0.4483405 (82)\ttotal: 2m 3s\tremaining: 22m 24s\n",
      "84:\tlearn: 0.1629895\ttest: 0.4486725\tbest: 0.4483405 (82)\ttotal: 2m 4s\tremaining: 22m 23s\n",
      "85:\tlearn: 0.1617693\ttest: 0.4474459\tbest: 0.4474459 (85)\ttotal: 2m 6s\tremaining: 22m 21s\n",
      "86:\tlearn: 0.1604497\ttest: 0.4474793\tbest: 0.4474459 (85)\ttotal: 2m 7s\tremaining: 22m 20s\n",
      "87:\tlearn: 0.1595801\ttest: 0.4463592\tbest: 0.4463592 (87)\ttotal: 2m 9s\tremaining: 22m 18s\n",
      "88:\tlearn: 0.1587843\ttest: 0.4453453\tbest: 0.4453453 (88)\ttotal: 2m 10s\tremaining: 22m 16s\n",
      "89:\tlearn: 0.1577337\ttest: 0.4451593\tbest: 0.4451593 (89)\ttotal: 2m 11s\tremaining: 22m 14s\n",
      "90:\tlearn: 0.1568364\ttest: 0.4455016\tbest: 0.4451593 (89)\ttotal: 2m 13s\tremaining: 22m 12s\n",
      "91:\tlearn: 0.1556273\ttest: 0.4448576\tbest: 0.4448576 (91)\ttotal: 2m 14s\tremaining: 22m 10s\n",
      "92:\tlearn: 0.1543751\ttest: 0.4452304\tbest: 0.4448576 (91)\ttotal: 2m 16s\tremaining: 22m 8s\n",
      "93:\tlearn: 0.1530208\ttest: 0.4446607\tbest: 0.4446607 (93)\ttotal: 2m 17s\tremaining: 22m 5s\n",
      "94:\tlearn: 0.1516246\ttest: 0.4437778\tbest: 0.4437778 (94)\ttotal: 2m 18s\tremaining: 22m 3s\n",
      "95:\tlearn: 0.1504053\ttest: 0.4440970\tbest: 0.4437778 (94)\ttotal: 2m 20s\tremaining: 22m 1s\n",
      "96:\tlearn: 0.1485406\ttest: 0.4435490\tbest: 0.4435490 (96)\ttotal: 2m 21s\tremaining: 21m 59s\n",
      "97:\tlearn: 0.1470849\ttest: 0.4435928\tbest: 0.4435490 (96)\ttotal: 2m 23s\tremaining: 21m 57s\n",
      "98:\tlearn: 0.1463406\ttest: 0.4418522\tbest: 0.4418522 (98)\ttotal: 2m 24s\tremaining: 21m 55s\n",
      "99:\tlearn: 0.1453123\ttest: 0.4396576\tbest: 0.4396576 (99)\ttotal: 2m 25s\tremaining: 21m 53s\n",
      "100:\tlearn: 0.1436505\ttest: 0.4398448\tbest: 0.4396576 (99)\ttotal: 2m 27s\tremaining: 21m 51s\n",
      "101:\tlearn: 0.1424981\ttest: 0.4403495\tbest: 0.4396576 (99)\ttotal: 2m 28s\tremaining: 21m 49s\n",
      "102:\tlearn: 0.1412040\ttest: 0.4387405\tbest: 0.4387405 (102)\ttotal: 2m 30s\tremaining: 21m 48s\n",
      "103:\tlearn: 0.1402854\ttest: 0.4388362\tbest: 0.4387405 (102)\ttotal: 2m 31s\tremaining: 21m 48s\n",
      "104:\tlearn: 0.1391881\ttest: 0.4385000\tbest: 0.4385000 (104)\ttotal: 2m 33s\tremaining: 21m 48s\n",
      "105:\tlearn: 0.1379202\ttest: 0.4384033\tbest: 0.4384033 (105)\ttotal: 2m 35s\tremaining: 21m 49s\n",
      "106:\tlearn: 0.1362586\ttest: 0.4379165\tbest: 0.4379165 (106)\ttotal: 2m 37s\tremaining: 21m 50s\n",
      "107:\tlearn: 0.1350498\ttest: 0.4389679\tbest: 0.4379165 (106)\ttotal: 2m 38s\tremaining: 21m 50s\n",
      "108:\tlearn: 0.1343873\ttest: 0.4391276\tbest: 0.4379165 (106)\ttotal: 2m 40s\tremaining: 21m 49s\n",
      "109:\tlearn: 0.1333348\ttest: 0.4389852\tbest: 0.4379165 (106)\ttotal: 2m 41s\tremaining: 21m 47s\n",
      "110:\tlearn: 0.1323980\ttest: 0.4393266\tbest: 0.4379165 (106)\ttotal: 2m 43s\tremaining: 21m 45s\n",
      "111:\tlearn: 0.1317598\ttest: 0.4398750\tbest: 0.4379165 (106)\ttotal: 2m 44s\tremaining: 21m 43s\n",
      "112:\tlearn: 0.1307525\ttest: 0.4395186\tbest: 0.4379165 (106)\ttotal: 2m 45s\tremaining: 21m 42s\n",
      "113:\tlearn: 0.1300061\ttest: 0.4388833\tbest: 0.4379165 (106)\ttotal: 2m 47s\tremaining: 21m 40s\n",
      "114:\tlearn: 0.1291397\ttest: 0.4391815\tbest: 0.4379165 (106)\ttotal: 2m 48s\tremaining: 21m 38s\n",
      "115:\tlearn: 0.1282964\ttest: 0.4385669\tbest: 0.4379165 (106)\ttotal: 2m 50s\tremaining: 21m 36s\n",
      "116:\tlearn: 0.1268292\ttest: 0.4383094\tbest: 0.4379165 (106)\ttotal: 2m 51s\tremaining: 21m 34s\n",
      "117:\tlearn: 0.1256368\ttest: 0.4380789\tbest: 0.4379165 (106)\ttotal: 2m 52s\tremaining: 21m 32s\n",
      "118:\tlearn: 0.1247828\ttest: 0.4381414\tbest: 0.4379165 (106)\ttotal: 2m 54s\tremaining: 21m 31s\n",
      "119:\tlearn: 0.1243346\ttest: 0.4380250\tbest: 0.4379165 (106)\ttotal: 2m 55s\tremaining: 21m 29s\n",
      "120:\tlearn: 0.1228498\ttest: 0.4366874\tbest: 0.4366874 (120)\ttotal: 2m 57s\tremaining: 21m 27s\n",
      "121:\tlearn: 0.1220881\ttest: 0.4365606\tbest: 0.4365606 (121)\ttotal: 2m 58s\tremaining: 21m 25s\n",
      "122:\tlearn: 0.1208573\ttest: 0.4364726\tbest: 0.4364726 (122)\ttotal: 3m\tremaining: 21m 24s\n",
      "123:\tlearn: 0.1198638\ttest: 0.4367726\tbest: 0.4364726 (122)\ttotal: 3m 1s\tremaining: 21m 22s\n",
      "124:\tlearn: 0.1186941\ttest: 0.4372949\tbest: 0.4364726 (122)\ttotal: 3m 2s\tremaining: 21m 20s\n",
      "125:\tlearn: 0.1177300\ttest: 0.4371183\tbest: 0.4364726 (122)\ttotal: 3m 4s\tremaining: 21m 18s\n",
      "126:\tlearn: 0.1165635\ttest: 0.4357208\tbest: 0.4357208 (126)\ttotal: 3m 5s\tremaining: 21m 16s\n",
      "127:\tlearn: 0.1157233\ttest: 0.4358280\tbest: 0.4357208 (126)\ttotal: 3m 7s\tremaining: 21m 14s\n",
      "128:\tlearn: 0.1147427\ttest: 0.4358032\tbest: 0.4357208 (126)\ttotal: 3m 8s\tremaining: 21m 13s\n",
      "129:\tlearn: 0.1142378\ttest: 0.4357599\tbest: 0.4357208 (126)\ttotal: 3m 10s\tremaining: 21m 11s\n",
      "130:\tlearn: 0.1137984\ttest: 0.4348251\tbest: 0.4348251 (130)\ttotal: 3m 11s\tremaining: 21m 9s\n",
      "131:\tlearn: 0.1127981\ttest: 0.4353872\tbest: 0.4348251 (130)\ttotal: 3m 12s\tremaining: 21m 8s\n",
      "132:\tlearn: 0.1119155\ttest: 0.4346891\tbest: 0.4346891 (132)\ttotal: 3m 14s\tremaining: 21m 6s\n",
      "133:\tlearn: 0.1114947\ttest: 0.4351143\tbest: 0.4346891 (132)\ttotal: 3m 15s\tremaining: 21m 4s\n",
      "134:\tlearn: 0.1106112\ttest: 0.4352614\tbest: 0.4346891 (132)\ttotal: 3m 17s\tremaining: 21m 2s\n",
      "135:\tlearn: 0.1097828\ttest: 0.4358655\tbest: 0.4346891 (132)\ttotal: 3m 18s\tremaining: 21m 1s\n",
      "136:\tlearn: 0.1087374\ttest: 0.4357920\tbest: 0.4346891 (132)\ttotal: 3m 19s\tremaining: 20m 59s\n",
      "137:\tlearn: 0.1078600\ttest: 0.4350497\tbest: 0.4346891 (132)\ttotal: 3m 21s\tremaining: 20m 57s\n",
      "138:\tlearn: 0.1069554\ttest: 0.4345834\tbest: 0.4345834 (138)\ttotal: 3m 22s\tremaining: 20m 56s\n",
      "139:\tlearn: 0.1060236\ttest: 0.4338572\tbest: 0.4338572 (139)\ttotal: 3m 24s\tremaining: 20m 54s\n",
      "140:\tlearn: 0.1051070\ttest: 0.4337461\tbest: 0.4337461 (140)\ttotal: 3m 25s\tremaining: 20m 53s\n",
      "141:\tlearn: 0.1046448\ttest: 0.4337154\tbest: 0.4337154 (141)\ttotal: 3m 27s\tremaining: 20m 51s\n",
      "142:\tlearn: 0.1038826\ttest: 0.4330966\tbest: 0.4330966 (142)\ttotal: 3m 28s\tremaining: 20m 49s\n",
      "143:\tlearn: 0.1031498\ttest: 0.4325893\tbest: 0.4325893 (143)\ttotal: 3m 30s\tremaining: 20m 48s\n",
      "144:\tlearn: 0.1025964\ttest: 0.4316178\tbest: 0.4316178 (144)\ttotal: 3m 31s\tremaining: 20m 47s\n",
      "145:\tlearn: 0.1018090\ttest: 0.4315993\tbest: 0.4315993 (145)\ttotal: 3m 33s\tremaining: 20m 45s\n",
      "146:\tlearn: 0.1012777\ttest: 0.4315582\tbest: 0.4315582 (146)\ttotal: 3m 34s\tremaining: 20m 44s\n",
      "147:\tlearn: 0.1006391\ttest: 0.4322453\tbest: 0.4315582 (146)\ttotal: 3m 35s\tremaining: 20m 43s\n",
      "148:\tlearn: 0.0998360\ttest: 0.4326237\tbest: 0.4315582 (146)\ttotal: 3m 37s\tremaining: 20m 41s\n",
      "149:\tlearn: 0.0990685\ttest: 0.4334005\tbest: 0.4315582 (146)\ttotal: 3m 38s\tremaining: 20m 40s\n",
      "150:\tlearn: 0.0985580\ttest: 0.4336845\tbest: 0.4315582 (146)\ttotal: 3m 40s\tremaining: 20m 38s\n",
      "151:\tlearn: 0.0977998\ttest: 0.4339243\tbest: 0.4315582 (146)\ttotal: 3m 41s\tremaining: 20m 37s\n",
      "152:\tlearn: 0.0973081\ttest: 0.4341564\tbest: 0.4315582 (146)\ttotal: 3m 43s\tremaining: 20m 36s\n",
      "153:\tlearn: 0.0970163\ttest: 0.4342615\tbest: 0.4315582 (146)\ttotal: 3m 44s\tremaining: 20m 36s\n",
      "154:\tlearn: 0.0962919\ttest: 0.4343842\tbest: 0.4315582 (146)\ttotal: 3m 46s\tremaining: 20m 35s\n",
      "155:\tlearn: 0.0956221\ttest: 0.4356966\tbest: 0.4315582 (146)\ttotal: 3m 48s\tremaining: 20m 34s\n",
      "156:\tlearn: 0.0946896\ttest: 0.4353889\tbest: 0.4315582 (146)\ttotal: 3m 49s\tremaining: 20m 33s\n",
      "157:\tlearn: 0.0942089\ttest: 0.4352469\tbest: 0.4315582 (146)\ttotal: 3m 51s\tremaining: 20m 33s\n",
      "158:\tlearn: 0.0934111\ttest: 0.4342220\tbest: 0.4315582 (146)\ttotal: 3m 52s\tremaining: 20m 32s\n",
      "159:\tlearn: 0.0924491\ttest: 0.4324973\tbest: 0.4315582 (146)\ttotal: 3m 54s\tremaining: 20m 31s\n",
      "160:\tlearn: 0.0917469\ttest: 0.4326074\tbest: 0.4315582 (146)\ttotal: 3m 56s\tremaining: 20m 31s\n",
      "161:\tlearn: 0.0914661\ttest: 0.4324664\tbest: 0.4315582 (146)\ttotal: 3m 57s\tremaining: 20m 30s\n",
      "162:\tlearn: 0.0906893\ttest: 0.4333822\tbest: 0.4315582 (146)\ttotal: 3m 59s\tremaining: 20m 29s\n",
      "163:\tlearn: 0.0900041\ttest: 0.4332230\tbest: 0.4315582 (146)\ttotal: 4m 1s\tremaining: 20m 29s\n",
      "164:\tlearn: 0.0892411\ttest: 0.4343817\tbest: 0.4315582 (146)\ttotal: 4m 2s\tremaining: 20m 28s\n",
      "165:\tlearn: 0.0886780\ttest: 0.4348420\tbest: 0.4315582 (146)\ttotal: 4m 4s\tremaining: 20m 27s\n",
      "166:\tlearn: 0.0882713\ttest: 0.4345230\tbest: 0.4315582 (146)\ttotal: 4m 5s\tremaining: 20m 26s\n",
      "167:\tlearn: 0.0874562\ttest: 0.4344709\tbest: 0.4315582 (146)\ttotal: 4m 7s\tremaining: 20m 25s\n",
      "168:\tlearn: 0.0869983\ttest: 0.4350142\tbest: 0.4315582 (146)\ttotal: 4m 9s\tremaining: 20m 25s\n",
      "169:\tlearn: 0.0863614\ttest: 0.4349374\tbest: 0.4315582 (146)\ttotal: 4m 10s\tremaining: 20m 24s\n",
      "170:\tlearn: 0.0859192\ttest: 0.4347489\tbest: 0.4315582 (146)\ttotal: 4m 12s\tremaining: 20m 23s\n",
      "171:\tlearn: 0.0850484\ttest: 0.4345602\tbest: 0.4315582 (146)\ttotal: 4m 13s\tremaining: 20m 22s\n",
      "172:\tlearn: 0.0842834\ttest: 0.4340448\tbest: 0.4315582 (146)\ttotal: 4m 15s\tremaining: 20m 21s\n",
      "173:\tlearn: 0.0836524\ttest: 0.4329782\tbest: 0.4315582 (146)\ttotal: 4m 17s\tremaining: 20m 21s\n",
      "174:\tlearn: 0.0829999\ttest: 0.4336413\tbest: 0.4315582 (146)\ttotal: 4m 18s\tremaining: 20m 20s\n",
      "175:\tlearn: 0.0821816\ttest: 0.4337327\tbest: 0.4315582 (146)\ttotal: 4m 20s\tremaining: 20m 19s\n",
      "176:\tlearn: 0.0814663\ttest: 0.4344036\tbest: 0.4315582 (146)\ttotal: 4m 21s\tremaining: 20m 18s\n",
      "177:\tlearn: 0.0810922\ttest: 0.4340340\tbest: 0.4315582 (146)\ttotal: 4m 23s\tremaining: 20m 17s\n",
      "178:\tlearn: 0.0805288\ttest: 0.4340789\tbest: 0.4315582 (146)\ttotal: 4m 25s\tremaining: 20m 16s\n",
      "179:\tlearn: 0.0799329\ttest: 0.4329224\tbest: 0.4315582 (146)\ttotal: 4m 26s\tremaining: 20m 16s\n",
      "180:\tlearn: 0.0791392\ttest: 0.4329926\tbest: 0.4315582 (146)\ttotal: 4m 28s\tremaining: 20m 14s\n",
      "181:\tlearn: 0.0785291\ttest: 0.4334094\tbest: 0.4315582 (146)\ttotal: 4m 30s\tremaining: 20m 13s\n",
      "182:\tlearn: 0.0780374\ttest: 0.4345819\tbest: 0.4315582 (146)\ttotal: 4m 31s\tremaining: 20m 12s\n",
      "183:\tlearn: 0.0773895\ttest: 0.4341852\tbest: 0.4315582 (146)\ttotal: 4m 33s\tremaining: 20m 12s\n",
      "184:\tlearn: 0.0766387\ttest: 0.4334143\tbest: 0.4315582 (146)\ttotal: 4m 34s\tremaining: 20m 11s\n",
      "185:\tlearn: 0.0761663\ttest: 0.4335425\tbest: 0.4315582 (146)\ttotal: 4m 36s\tremaining: 20m 10s\n",
      "186:\tlearn: 0.0757398\ttest: 0.4332769\tbest: 0.4315582 (146)\ttotal: 4m 38s\tremaining: 20m 9s\n",
      "187:\tlearn: 0.0751143\ttest: 0.4347795\tbest: 0.4315582 (146)\ttotal: 4m 39s\tremaining: 20m 8s\n",
      "188:\tlearn: 0.0744429\ttest: 0.4353848\tbest: 0.4315582 (146)\ttotal: 4m 41s\tremaining: 20m 7s\n",
      "189:\tlearn: 0.0740763\ttest: 0.4356884\tbest: 0.4315582 (146)\ttotal: 4m 42s\tremaining: 20m 6s\n",
      "190:\tlearn: 0.0738173\ttest: 0.4354983\tbest: 0.4315582 (146)\ttotal: 4m 44s\tremaining: 20m 5s\n",
      "191:\tlearn: 0.0732314\ttest: 0.4355987\tbest: 0.4315582 (146)\ttotal: 4m 46s\tremaining: 20m 4s\n",
      "192:\tlearn: 0.0726313\ttest: 0.4358287\tbest: 0.4315582 (146)\ttotal: 4m 47s\tremaining: 20m 3s\n",
      "193:\tlearn: 0.0718280\ttest: 0.4347845\tbest: 0.4315582 (146)\ttotal: 4m 49s\tremaining: 20m 3s\n",
      "194:\tlearn: 0.0713807\ttest: 0.4341930\tbest: 0.4315582 (146)\ttotal: 4m 51s\tremaining: 20m 1s\n",
      "195:\tlearn: 0.0710018\ttest: 0.4341140\tbest: 0.4315582 (146)\ttotal: 4m 52s\tremaining: 20m\n",
      "196:\tlearn: 0.0702591\ttest: 0.4348005\tbest: 0.4315582 (146)\ttotal: 4m 54s\tremaining: 19m 59s\n",
      "197:\tlearn: 0.0698143\ttest: 0.4343908\tbest: 0.4315582 (146)\ttotal: 4m 55s\tremaining: 19m 58s\n",
      "198:\tlearn: 0.0694865\ttest: 0.4345378\tbest: 0.4315582 (146)\ttotal: 4m 57s\tremaining: 19m 57s\n",
      "199:\tlearn: 0.0691461\ttest: 0.4355968\tbest: 0.4315582 (146)\ttotal: 4m 58s\tremaining: 19m 55s\n",
      "200:\tlearn: 0.0684924\ttest: 0.4357029\tbest: 0.4315582 (146)\ttotal: 5m\tremaining: 19m 54s\n",
      "201:\tlearn: 0.0679580\ttest: 0.4358637\tbest: 0.4315582 (146)\ttotal: 5m 2s\tremaining: 19m 54s\n",
      "202:\tlearn: 0.0675451\ttest: 0.4360980\tbest: 0.4315582 (146)\ttotal: 5m 3s\tremaining: 19m 53s\n",
      "203:\tlearn: 0.0669176\ttest: 0.4363857\tbest: 0.4315582 (146)\ttotal: 5m 5s\tremaining: 19m 52s\n",
      "204:\tlearn: 0.0665632\ttest: 0.4364547\tbest: 0.4315582 (146)\ttotal: 5m 7s\tremaining: 19m 51s\n",
      "205:\tlearn: 0.0661784\ttest: 0.4366561\tbest: 0.4315582 (146)\ttotal: 5m 8s\tremaining: 19m 50s\n",
      "206:\tlearn: 0.0656582\ttest: 0.4364359\tbest: 0.4315582 (146)\ttotal: 5m 10s\tremaining: 19m 48s\n",
      "207:\tlearn: 0.0652946\ttest: 0.4363198\tbest: 0.4315582 (146)\ttotal: 5m 11s\tremaining: 19m 47s\n",
      "208:\tlearn: 0.0647949\ttest: 0.4355652\tbest: 0.4315582 (146)\ttotal: 5m 13s\tremaining: 19m 46s\n",
      "209:\tlearn: 0.0642881\ttest: 0.4364213\tbest: 0.4315582 (146)\ttotal: 5m 15s\tremaining: 19m 45s\n",
      "210:\tlearn: 0.0638026\ttest: 0.4363561\tbest: 0.4315582 (146)\ttotal: 5m 16s\tremaining: 19m 44s\n",
      "211:\tlearn: 0.0633195\ttest: 0.4362015\tbest: 0.4315582 (146)\ttotal: 5m 18s\tremaining: 19m 43s\n",
      "212:\tlearn: 0.0629442\ttest: 0.4366074\tbest: 0.4315582 (146)\ttotal: 5m 19s\tremaining: 19m 42s\n",
      "213:\tlearn: 0.0626393\ttest: 0.4358883\tbest: 0.4315582 (146)\ttotal: 5m 21s\tremaining: 19m 41s\n",
      "214:\tlearn: 0.0621453\ttest: 0.4361049\tbest: 0.4315582 (146)\ttotal: 5m 23s\tremaining: 19m 40s\n",
      "215:\tlearn: 0.0618341\ttest: 0.4361882\tbest: 0.4315582 (146)\ttotal: 5m 24s\tremaining: 19m 39s\n",
      "216:\tlearn: 0.0614183\ttest: 0.4369164\tbest: 0.4315582 (146)\ttotal: 5m 26s\tremaining: 19m 38s\n",
      "217:\tlearn: 0.0608412\ttest: 0.4360191\tbest: 0.4315582 (146)\ttotal: 5m 28s\tremaining: 19m 37s\n",
      "218:\tlearn: 0.0604016\ttest: 0.4365049\tbest: 0.4315582 (146)\ttotal: 5m 29s\tremaining: 19m 35s\n",
      "219:\tlearn: 0.0601643\ttest: 0.4361419\tbest: 0.4315582 (146)\ttotal: 5m 30s\tremaining: 19m 33s\n",
      "220:\tlearn: 0.0597875\ttest: 0.4363551\tbest: 0.4315582 (146)\ttotal: 5m 32s\tremaining: 19m 31s\n",
      "221:\tlearn: 0.0594700\ttest: 0.4364593\tbest: 0.4315582 (146)\ttotal: 5m 33s\tremaining: 19m 29s\n",
      "222:\tlearn: 0.0591515\ttest: 0.4362259\tbest: 0.4315582 (146)\ttotal: 5m 35s\tremaining: 19m 28s\n",
      "223:\tlearn: 0.0586665\ttest: 0.4361643\tbest: 0.4315582 (146)\ttotal: 5m 36s\tremaining: 19m 26s\n",
      "224:\tlearn: 0.0581836\ttest: 0.4362426\tbest: 0.4315582 (146)\ttotal: 5m 38s\tremaining: 19m 24s\n",
      "225:\tlearn: 0.0578042\ttest: 0.4354188\tbest: 0.4315582 (146)\ttotal: 5m 39s\tremaining: 19m 22s\n",
      "226:\tlearn: 0.0572348\ttest: 0.4355974\tbest: 0.4315582 (146)\ttotal: 5m 40s\tremaining: 19m 21s\n",
      "227:\tlearn: 0.0567708\ttest: 0.4352444\tbest: 0.4315582 (146)\ttotal: 5m 42s\tremaining: 19m 19s\n",
      "228:\tlearn: 0.0563558\ttest: 0.4357507\tbest: 0.4315582 (146)\ttotal: 5m 44s\tremaining: 19m 18s\n",
      "229:\tlearn: 0.0561534\ttest: 0.4350294\tbest: 0.4315582 (146)\ttotal: 5m 45s\tremaining: 19m 16s\n",
      "230:\tlearn: 0.0556925\ttest: 0.4349821\tbest: 0.4315582 (146)\ttotal: 5m 47s\tremaining: 19m 15s\n",
      "231:\tlearn: 0.0552120\ttest: 0.4350827\tbest: 0.4315582 (146)\ttotal: 5m 48s\tremaining: 19m 14s\n",
      "232:\tlearn: 0.0546848\ttest: 0.4358663\tbest: 0.4315582 (146)\ttotal: 5m 50s\tremaining: 19m 13s\n",
      "233:\tlearn: 0.0543510\ttest: 0.4358021\tbest: 0.4315582 (146)\ttotal: 5m 51s\tremaining: 19m 11s\n",
      "234:\tlearn: 0.0539723\ttest: 0.4355908\tbest: 0.4315582 (146)\ttotal: 5m 53s\tremaining: 19m 10s\n",
      "235:\tlearn: 0.0535185\ttest: 0.4357810\tbest: 0.4315582 (146)\ttotal: 5m 55s\tremaining: 19m 9s\n",
      "236:\tlearn: 0.0531663\ttest: 0.4352300\tbest: 0.4315582 (146)\ttotal: 5m 56s\tremaining: 19m 8s\n",
      "237:\tlearn: 0.0528965\ttest: 0.4350775\tbest: 0.4315582 (146)\ttotal: 5m 58s\tremaining: 19m 7s\n",
      "238:\tlearn: 0.0525777\ttest: 0.4349802\tbest: 0.4315582 (146)\ttotal: 5m 59s\tremaining: 19m 5s\n",
      "239:\tlearn: 0.0522941\ttest: 0.4348613\tbest: 0.4315582 (146)\ttotal: 6m 1s\tremaining: 19m 4s\n",
      "240:\tlearn: 0.0520637\ttest: 0.4349799\tbest: 0.4315582 (146)\ttotal: 6m 3s\tremaining: 19m 3s\n",
      "241:\tlearn: 0.0517223\ttest: 0.4341390\tbest: 0.4315582 (146)\ttotal: 6m 4s\tremaining: 19m 1s\n",
      "242:\tlearn: 0.0513673\ttest: 0.4347991\tbest: 0.4315582 (146)\ttotal: 6m 6s\tremaining: 19m\n",
      "243:\tlearn: 0.0509399\ttest: 0.4348489\tbest: 0.4315582 (146)\ttotal: 6m 7s\tremaining: 18m 59s\n",
      "244:\tlearn: 0.0506395\ttest: 0.4347220\tbest: 0.4315582 (146)\ttotal: 6m 9s\tremaining: 18m 58s\n",
      "245:\tlearn: 0.0502426\ttest: 0.4346449\tbest: 0.4315582 (146)\ttotal: 6m 11s\tremaining: 18m 57s\n",
      "246:\tlearn: 0.0497151\ttest: 0.4339369\tbest: 0.4315582 (146)\ttotal: 6m 12s\tremaining: 18m 56s\n",
      "247:\tlearn: 0.0493783\ttest: 0.4346312\tbest: 0.4315582 (146)\ttotal: 6m 14s\tremaining: 18m 54s\n",
      "248:\tlearn: 0.0489406\ttest: 0.4343455\tbest: 0.4315582 (146)\ttotal: 6m 15s\tremaining: 18m 53s\n",
      "249:\tlearn: 0.0486137\ttest: 0.4333991\tbest: 0.4315582 (146)\ttotal: 6m 17s\tremaining: 18m 52s\n",
      "250:\tlearn: 0.0482312\ttest: 0.4327624\tbest: 0.4315582 (146)\ttotal: 6m 19s\tremaining: 18m 51s\n",
      "251:\tlearn: 0.0479901\ttest: 0.4327507\tbest: 0.4315582 (146)\ttotal: 6m 20s\tremaining: 18m 49s\n",
      "252:\tlearn: 0.0476294\ttest: 0.4324467\tbest: 0.4315582 (146)\ttotal: 6m 22s\tremaining: 18m 48s\n",
      "253:\tlearn: 0.0473817\ttest: 0.4325677\tbest: 0.4315582 (146)\ttotal: 6m 23s\tremaining: 18m 47s\n",
      "254:\tlearn: 0.0470361\ttest: 0.4326693\tbest: 0.4315582 (146)\ttotal: 6m 25s\tremaining: 18m 46s\n",
      "255:\tlearn: 0.0468021\ttest: 0.4318782\tbest: 0.4315582 (146)\ttotal: 6m 27s\tremaining: 18m 45s\n",
      "256:\tlearn: 0.0466425\ttest: 0.4320834\tbest: 0.4315582 (146)\ttotal: 6m 28s\tremaining: 18m 43s\n",
      "257:\tlearn: 0.0463717\ttest: 0.4329319\tbest: 0.4315582 (146)\ttotal: 6m 30s\tremaining: 18m 42s\n",
      "258:\tlearn: 0.0460825\ttest: 0.4331767\tbest: 0.4315582 (146)\ttotal: 6m 31s\tremaining: 18m 41s\n",
      "259:\tlearn: 0.0459602\ttest: 0.4330392\tbest: 0.4315582 (146)\ttotal: 6m 33s\tremaining: 18m 39s\n",
      "260:\tlearn: 0.0456776\ttest: 0.4334682\tbest: 0.4315582 (146)\ttotal: 6m 35s\tremaining: 18m 38s\n",
      "261:\tlearn: 0.0453250\ttest: 0.4332979\tbest: 0.4315582 (146)\ttotal: 6m 36s\tremaining: 18m 37s\n",
      "262:\tlearn: 0.0449798\ttest: 0.4330398\tbest: 0.4315582 (146)\ttotal: 6m 38s\tremaining: 18m 36s\n",
      "263:\tlearn: 0.0448250\ttest: 0.4331568\tbest: 0.4315582 (146)\ttotal: 6m 39s\tremaining: 18m 35s\n",
      "264:\tlearn: 0.0445230\ttest: 0.4325295\tbest: 0.4315582 (146)\ttotal: 6m 41s\tremaining: 18m 33s\n",
      "265:\tlearn: 0.0441308\ttest: 0.4329553\tbest: 0.4315582 (146)\ttotal: 6m 43s\tremaining: 18m 32s\n",
      "266:\tlearn: 0.0439026\ttest: 0.4327233\tbest: 0.4315582 (146)\ttotal: 6m 44s\tremaining: 18m 31s\n",
      "267:\tlearn: 0.0436112\ttest: 0.4320763\tbest: 0.4315582 (146)\ttotal: 6m 46s\tremaining: 18m 30s\n",
      "268:\tlearn: 0.0434038\ttest: 0.4324880\tbest: 0.4315582 (146)\ttotal: 6m 48s\tremaining: 18m 28s\n",
      "269:\tlearn: 0.0431725\ttest: 0.4327675\tbest: 0.4315582 (146)\ttotal: 6m 49s\tremaining: 18m 27s\n",
      "270:\tlearn: 0.0428896\ttest: 0.4319646\tbest: 0.4315582 (146)\ttotal: 6m 51s\tremaining: 18m 26s\n",
      "271:\tlearn: 0.0425701\ttest: 0.4316041\tbest: 0.4315582 (146)\ttotal: 6m 52s\tremaining: 18m 25s\n",
      "272:\tlearn: 0.0423220\ttest: 0.4311945\tbest: 0.4311945 (272)\ttotal: 6m 54s\tremaining: 18m 23s\n",
      "273:\tlearn: 0.0421356\ttest: 0.4313463\tbest: 0.4311945 (272)\ttotal: 6m 56s\tremaining: 18m 22s\n",
      "274:\tlearn: 0.0418514\ttest: 0.4308612\tbest: 0.4308612 (274)\ttotal: 6m 57s\tremaining: 18m 21s\n",
      "275:\tlearn: 0.0415573\ttest: 0.4310092\tbest: 0.4308612 (274)\ttotal: 6m 59s\tremaining: 18m 19s\n",
      "276:\tlearn: 0.0412301\ttest: 0.4313654\tbest: 0.4308612 (274)\ttotal: 7m\tremaining: 18m 18s\n",
      "277:\tlearn: 0.0409406\ttest: 0.4312963\tbest: 0.4308612 (274)\ttotal: 7m 2s\tremaining: 18m 16s\n",
      "278:\tlearn: 0.0407686\ttest: 0.4312882\tbest: 0.4308612 (274)\ttotal: 7m 4s\tremaining: 18m 15s\n",
      "279:\tlearn: 0.0404333\ttest: 0.4309990\tbest: 0.4308612 (274)\ttotal: 7m 5s\tremaining: 18m 14s\n",
      "280:\tlearn: 0.0401623\ttest: 0.4312480\tbest: 0.4308612 (274)\ttotal: 7m 7s\tremaining: 18m 13s\n",
      "281:\tlearn: 0.0400266\ttest: 0.4317192\tbest: 0.4308612 (274)\ttotal: 7m 9s\tremaining: 18m 12s\n",
      "282:\tlearn: 0.0398163\ttest: 0.4319819\tbest: 0.4308612 (274)\ttotal: 7m 10s\tremaining: 18m 11s\n",
      "283:\tlearn: 0.0396104\ttest: 0.4310548\tbest: 0.4308612 (274)\ttotal: 7m 12s\tremaining: 18m 10s\n",
      "284:\tlearn: 0.0393741\ttest: 0.4301692\tbest: 0.4301692 (284)\ttotal: 7m 14s\tremaining: 18m 9s\n",
      "285:\tlearn: 0.0391929\ttest: 0.4304078\tbest: 0.4301692 (284)\ttotal: 7m 15s\tremaining: 18m 8s\n",
      "286:\tlearn: 0.0388629\ttest: 0.4304698\tbest: 0.4301692 (284)\ttotal: 7m 17s\tremaining: 18m 6s\n",
      "287:\tlearn: 0.0385637\ttest: 0.4312372\tbest: 0.4301692 (284)\ttotal: 7m 19s\tremaining: 18m 5s\n",
      "288:\tlearn: 0.0383169\ttest: 0.4315794\tbest: 0.4301692 (284)\ttotal: 7m 20s\tremaining: 18m 4s\n",
      "289:\tlearn: 0.0381280\ttest: 0.4317257\tbest: 0.4301692 (284)\ttotal: 7m 22s\tremaining: 18m 2s\n",
      "290:\tlearn: 0.0378425\ttest: 0.4313102\tbest: 0.4301692 (284)\ttotal: 7m 24s\tremaining: 18m 1s\n",
      "291:\tlearn: 0.0376133\ttest: 0.4307879\tbest: 0.4301692 (284)\ttotal: 7m 25s\tremaining: 18m\n",
      "292:\tlearn: 0.0374470\ttest: 0.4302640\tbest: 0.4301692 (284)\ttotal: 7m 27s\tremaining: 17m 59s\n",
      "293:\tlearn: 0.0373305\ttest: 0.4306945\tbest: 0.4301692 (284)\ttotal: 7m 28s\tremaining: 17m 58s\n",
      "294:\tlearn: 0.0371823\ttest: 0.4306923\tbest: 0.4301692 (284)\ttotal: 7m 30s\tremaining: 17m 56s\n",
      "295:\tlearn: 0.0370076\ttest: 0.4312679\tbest: 0.4301692 (284)\ttotal: 7m 32s\tremaining: 17m 55s\n",
      "296:\tlearn: 0.0368345\ttest: 0.4314279\tbest: 0.4301692 (284)\ttotal: 7m 33s\tremaining: 17m 53s\n",
      "297:\tlearn: 0.0365457\ttest: 0.4314341\tbest: 0.4301692 (284)\ttotal: 7m 35s\tremaining: 17m 52s\n",
      "298:\tlearn: 0.0363706\ttest: 0.4307415\tbest: 0.4301692 (284)\ttotal: 7m 36s\tremaining: 17m 51s\n",
      "299:\tlearn: 0.0361491\ttest: 0.4302905\tbest: 0.4301692 (284)\ttotal: 7m 38s\tremaining: 17m 49s\n",
      "300:\tlearn: 0.0359560\ttest: 0.4302211\tbest: 0.4301692 (284)\ttotal: 7m 40s\tremaining: 17m 48s\n",
      "301:\tlearn: 0.0357575\ttest: 0.4304744\tbest: 0.4301692 (284)\ttotal: 7m 41s\tremaining: 17m 47s\n",
      "302:\tlearn: 0.0356042\ttest: 0.4301470\tbest: 0.4301470 (302)\ttotal: 7m 43s\tremaining: 17m 45s\n",
      "303:\tlearn: 0.0353026\ttest: 0.4302344\tbest: 0.4301470 (302)\ttotal: 7m 44s\tremaining: 17m 44s\n",
      "304:\tlearn: 0.0351174\ttest: 0.4309379\tbest: 0.4301470 (302)\ttotal: 7m 46s\tremaining: 17m 42s\n",
      "305:\tlearn: 0.0349492\ttest: 0.4309245\tbest: 0.4301470 (302)\ttotal: 7m 48s\tremaining: 17m 41s\n",
      "306:\tlearn: 0.0348273\ttest: 0.4313813\tbest: 0.4301470 (302)\ttotal: 7m 49s\tremaining: 17m 40s\n",
      "307:\tlearn: 0.0346492\ttest: 0.4314479\tbest: 0.4301470 (302)\ttotal: 7m 51s\tremaining: 17m 38s\n",
      "308:\tlearn: 0.0344230\ttest: 0.4318390\tbest: 0.4301470 (302)\ttotal: 7m 52s\tremaining: 17m 37s\n",
      "309:\tlearn: 0.0342710\ttest: 0.4326386\tbest: 0.4301470 (302)\ttotal: 7m 54s\tremaining: 17m 36s\n",
      "310:\tlearn: 0.0340048\ttest: 0.4324535\tbest: 0.4301470 (302)\ttotal: 7m 56s\tremaining: 17m 34s\n",
      "311:\tlearn: 0.0338385\ttest: 0.4324934\tbest: 0.4301470 (302)\ttotal: 7m 57s\tremaining: 17m 33s\n",
      "312:\tlearn: 0.0335877\ttest: 0.4319565\tbest: 0.4301470 (302)\ttotal: 7m 59s\tremaining: 17m 32s\n",
      "313:\tlearn: 0.0334354\ttest: 0.4318938\tbest: 0.4301470 (302)\ttotal: 8m\tremaining: 17m 30s\n",
      "314:\tlearn: 0.0332886\ttest: 0.4318765\tbest: 0.4301470 (302)\ttotal: 8m 2s\tremaining: 17m 29s\n",
      "315:\tlearn: 0.0330697\ttest: 0.4319558\tbest: 0.4301470 (302)\ttotal: 8m 4s\tremaining: 17m 27s\n",
      "316:\tlearn: 0.0329426\ttest: 0.4316352\tbest: 0.4301470 (302)\ttotal: 8m 5s\tremaining: 17m 26s\n",
      "317:\tlearn: 0.0327128\ttest: 0.4314654\tbest: 0.4301470 (302)\ttotal: 8m 7s\tremaining: 17m 24s\n",
      "318:\tlearn: 0.0324828\ttest: 0.4312318\tbest: 0.4301470 (302)\ttotal: 8m 8s\tremaining: 17m 23s\n",
      "319:\tlearn: 0.0323912\ttest: 0.4317408\tbest: 0.4301470 (302)\ttotal: 8m 10s\tremaining: 17m 21s\n",
      "320:\tlearn: 0.0322319\ttest: 0.4314473\tbest: 0.4301470 (302)\ttotal: 8m 11s\tremaining: 17m 19s\n",
      "321:\tlearn: 0.0319955\ttest: 0.4312088\tbest: 0.4301470 (302)\ttotal: 8m 12s\tremaining: 17m 17s\n",
      "322:\tlearn: 0.0317483\ttest: 0.4312859\tbest: 0.4301470 (302)\ttotal: 8m 14s\tremaining: 17m 16s\n",
      "323:\tlearn: 0.0315517\ttest: 0.4317327\tbest: 0.4301470 (302)\ttotal: 8m 15s\tremaining: 17m 14s\n",
      "324:\tlearn: 0.0314289\ttest: 0.4316950\tbest: 0.4301470 (302)\ttotal: 8m 17s\tremaining: 17m 12s\n",
      "325:\tlearn: 0.0312415\ttest: 0.4317288\tbest: 0.4301470 (302)\ttotal: 8m 18s\tremaining: 17m 10s\n",
      "326:\tlearn: 0.0309927\ttest: 0.4318185\tbest: 0.4301470 (302)\ttotal: 8m 19s\tremaining: 17m 8s\n",
      "327:\tlearn: 0.0308938\ttest: 0.4320169\tbest: 0.4301470 (302)\ttotal: 8m 21s\tremaining: 17m 7s\n",
      "328:\tlearn: 0.0307149\ttest: 0.4317291\tbest: 0.4301470 (302)\ttotal: 8m 22s\tremaining: 17m 5s\n",
      "329:\tlearn: 0.0305065\ttest: 0.4317828\tbest: 0.4301470 (302)\ttotal: 8m 24s\tremaining: 17m 3s\n",
      "330:\tlearn: 0.0303047\ttest: 0.4318765\tbest: 0.4301470 (302)\ttotal: 8m 25s\tremaining: 17m 1s\n",
      "331:\tlearn: 0.0302328\ttest: 0.4319205\tbest: 0.4301470 (302)\ttotal: 8m 26s\tremaining: 17m\n",
      "332:\tlearn: 0.0300556\ttest: 0.4319474\tbest: 0.4301470 (302)\ttotal: 8m 28s\tremaining: 16m 58s\n",
      "333:\tlearn: 0.0298517\ttest: 0.4319991\tbest: 0.4301470 (302)\ttotal: 8m 29s\tremaining: 16m 56s\n",
      "334:\tlearn: 0.0296814\ttest: 0.4316474\tbest: 0.4301470 (302)\ttotal: 8m 31s\tremaining: 16m 54s\n",
      "335:\tlearn: 0.0296003\ttest: 0.4324829\tbest: 0.4301470 (302)\ttotal: 8m 32s\tremaining: 16m 53s\n",
      "336:\tlearn: 0.0294103\ttest: 0.4322482\tbest: 0.4301470 (302)\ttotal: 8m 34s\tremaining: 16m 51s\n",
      "337:\tlearn: 0.0292349\ttest: 0.4317706\tbest: 0.4301470 (302)\ttotal: 8m 35s\tremaining: 16m 49s\n",
      "338:\tlearn: 0.0291227\ttest: 0.4318657\tbest: 0.4301470 (302)\ttotal: 8m 36s\tremaining: 16m 48s\n",
      "339:\tlearn: 0.0289194\ttest: 0.4318455\tbest: 0.4301470 (302)\ttotal: 8m 38s\tremaining: 16m 46s\n",
      "340:\tlearn: 0.0287879\ttest: 0.4325017\tbest: 0.4301470 (302)\ttotal: 8m 39s\tremaining: 16m 44s\n",
      "341:\tlearn: 0.0286745\ttest: 0.4330223\tbest: 0.4301470 (302)\ttotal: 8m 41s\tremaining: 16m 42s\n",
      "342:\tlearn: 0.0285185\ttest: 0.4328997\tbest: 0.4301470 (302)\ttotal: 8m 42s\tremaining: 16m 41s\n",
      "343:\tlearn: 0.0284267\ttest: 0.4329438\tbest: 0.4301470 (302)\ttotal: 8m 44s\tremaining: 16m 39s\n",
      "344:\tlearn: 0.0282514\ttest: 0.4325873\tbest: 0.4301470 (302)\ttotal: 8m 45s\tremaining: 16m 37s\n",
      "345:\tlearn: 0.0281493\ttest: 0.4332178\tbest: 0.4301470 (302)\ttotal: 8m 46s\tremaining: 16m 35s\n",
      "346:\tlearn: 0.0279369\ttest: 0.4336644\tbest: 0.4301470 (302)\ttotal: 8m 48s\tremaining: 16m 34s\n",
      "347:\tlearn: 0.0277691\ttest: 0.4330768\tbest: 0.4301470 (302)\ttotal: 8m 49s\tremaining: 16m 32s\n",
      "348:\tlearn: 0.0275796\ttest: 0.4328581\tbest: 0.4301470 (302)\ttotal: 8m 51s\tremaining: 16m 30s\n",
      "349:\tlearn: 0.0274241\ttest: 0.4328446\tbest: 0.4301470 (302)\ttotal: 8m 52s\tremaining: 16m 29s\n",
      "350:\tlearn: 0.0273468\ttest: 0.4332367\tbest: 0.4301470 (302)\ttotal: 8m 53s\tremaining: 16m 27s\n",
      "351:\tlearn: 0.0271991\ttest: 0.4332045\tbest: 0.4301470 (302)\ttotal: 8m 55s\tremaining: 16m 25s\n",
      "352:\tlearn: 0.0270891\ttest: 0.4330798\tbest: 0.4301470 (302)\ttotal: 8m 56s\tremaining: 16m 23s\n",
      "353:\tlearn: 0.0268879\ttest: 0.4326292\tbest: 0.4301470 (302)\ttotal: 8m 58s\tremaining: 16m 22s\n",
      "354:\tlearn: 0.0267040\ttest: 0.4327509\tbest: 0.4301470 (302)\ttotal: 8m 59s\tremaining: 16m 20s\n",
      "355:\tlearn: 0.0265713\ttest: 0.4325496\tbest: 0.4301470 (302)\ttotal: 9m 1s\tremaining: 16m 18s\n",
      "356:\tlearn: 0.0264817\ttest: 0.4327485\tbest: 0.4301470 (302)\ttotal: 9m 2s\tremaining: 16m 17s\n",
      "357:\tlearn: 0.0263809\ttest: 0.4320898\tbest: 0.4301470 (302)\ttotal: 9m 3s\tremaining: 16m 15s\n",
      "358:\tlearn: 0.0262195\ttest: 0.4325924\tbest: 0.4301470 (302)\ttotal: 9m 5s\tremaining: 16m 13s\n",
      "359:\tlearn: 0.0261048\ttest: 0.4323003\tbest: 0.4301470 (302)\ttotal: 9m 6s\tremaining: 16m 11s\n",
      "360:\tlearn: 0.0259754\ttest: 0.4320037\tbest: 0.4301470 (302)\ttotal: 9m 8s\tremaining: 16m 10s\n",
      "361:\tlearn: 0.0258421\ttest: 0.4320430\tbest: 0.4301470 (302)\ttotal: 9m 9s\tremaining: 16m 8s\n",
      "362:\tlearn: 0.0257109\ttest: 0.4322114\tbest: 0.4301470 (302)\ttotal: 9m 11s\tremaining: 16m 6s\n",
      "363:\tlearn: 0.0256287\ttest: 0.4320250\tbest: 0.4301470 (302)\ttotal: 9m 12s\tremaining: 16m 5s\n",
      "364:\tlearn: 0.0254891\ttest: 0.4319232\tbest: 0.4301470 (302)\ttotal: 9m 14s\tremaining: 16m 4s\n",
      "365:\tlearn: 0.0253602\ttest: 0.4320582\tbest: 0.4301470 (302)\ttotal: 9m 15s\tremaining: 16m 2s\n",
      "366:\tlearn: 0.0252693\ttest: 0.4321942\tbest: 0.4301470 (302)\ttotal: 9m 17s\tremaining: 16m 1s\n",
      "367:\tlearn: 0.0251548\ttest: 0.4312006\tbest: 0.4301470 (302)\ttotal: 9m 18s\tremaining: 15m 59s\n",
      "368:\tlearn: 0.0250813\ttest: 0.4312182\tbest: 0.4301470 (302)\ttotal: 9m 20s\tremaining: 15m 58s\n",
      "369:\tlearn: 0.0250041\ttest: 0.4308886\tbest: 0.4301470 (302)\ttotal: 9m 21s\tremaining: 15m 56s\n",
      "370:\tlearn: 0.0248566\ttest: 0.4309642\tbest: 0.4301470 (302)\ttotal: 9m 23s\tremaining: 15m 55s\n",
      "371:\tlearn: 0.0247651\ttest: 0.4314521\tbest: 0.4301470 (302)\ttotal: 9m 25s\tremaining: 15m 53s\n",
      "372:\tlearn: 0.0246251\ttest: 0.4311544\tbest: 0.4301470 (302)\ttotal: 9m 26s\tremaining: 15m 52s\n",
      "373:\tlearn: 0.0244944\ttest: 0.4312160\tbest: 0.4301470 (302)\ttotal: 9m 28s\tremaining: 15m 51s\n",
      "374:\tlearn: 0.0243374\ttest: 0.4310400\tbest: 0.4301470 (302)\ttotal: 9m 29s\tremaining: 15m 49s\n",
      "375:\tlearn: 0.0242151\ttest: 0.4310750\tbest: 0.4301470 (302)\ttotal: 9m 31s\tremaining: 15m 48s\n",
      "376:\tlearn: 0.0240756\ttest: 0.4310857\tbest: 0.4301470 (302)\ttotal: 9m 32s\tremaining: 15m 46s\n",
      "377:\tlearn: 0.0239701\ttest: 0.4310187\tbest: 0.4301470 (302)\ttotal: 9m 34s\tremaining: 15m 45s\n",
      "378:\tlearn: 0.0239113\ttest: 0.4313964\tbest: 0.4301470 (302)\ttotal: 9m 35s\tremaining: 15m 43s\n",
      "379:\tlearn: 0.0237919\ttest: 0.4306291\tbest: 0.4301470 (302)\ttotal: 9m 37s\tremaining: 15m 42s\n",
      "380:\tlearn: 0.0237025\ttest: 0.4310210\tbest: 0.4301470 (302)\ttotal: 9m 39s\tremaining: 15m 40s\n",
      "381:\tlearn: 0.0235924\ttest: 0.4315940\tbest: 0.4301470 (302)\ttotal: 9m 40s\tremaining: 15m 39s\n",
      "382:\tlearn: 0.0235058\ttest: 0.4320518\tbest: 0.4301470 (302)\ttotal: 9m 42s\tremaining: 15m 37s\n",
      "383:\tlearn: 0.0234508\ttest: 0.4317902\tbest: 0.4301470 (302)\ttotal: 9m 43s\tremaining: 15m 36s\n",
      "384:\tlearn: 0.0233656\ttest: 0.4320588\tbest: 0.4301470 (302)\ttotal: 9m 45s\tremaining: 15m 35s\n",
      "385:\tlearn: 0.0232500\ttest: 0.4321177\tbest: 0.4301470 (302)\ttotal: 9m 46s\tremaining: 15m 33s\n",
      "386:\tlearn: 0.0231873\ttest: 0.4319545\tbest: 0.4301470 (302)\ttotal: 9m 48s\tremaining: 15m 32s\n",
      "387:\tlearn: 0.0231018\ttest: 0.4323547\tbest: 0.4301470 (302)\ttotal: 9m 49s\tremaining: 15m 30s\n",
      "388:\tlearn: 0.0229787\ttest: 0.4329368\tbest: 0.4301470 (302)\ttotal: 9m 51s\tremaining: 15m 29s\n",
      "389:\tlearn: 0.0228773\ttest: 0.4330239\tbest: 0.4301470 (302)\ttotal: 9m 53s\tremaining: 15m 27s\n",
      "390:\tlearn: 0.0227682\ttest: 0.4333499\tbest: 0.4301470 (302)\ttotal: 9m 54s\tremaining: 15m 26s\n",
      "391:\tlearn: 0.0226859\ttest: 0.4334627\tbest: 0.4301470 (302)\ttotal: 9m 56s\tremaining: 15m 24s\n",
      "392:\tlearn: 0.0225629\ttest: 0.4332958\tbest: 0.4301470 (302)\ttotal: 9m 57s\tremaining: 15m 23s\n",
      "393:\tlearn: 0.0224325\ttest: 0.4337794\tbest: 0.4301470 (302)\ttotal: 9m 59s\tremaining: 15m 21s\n",
      "394:\tlearn: 0.0223591\ttest: 0.4337846\tbest: 0.4301470 (302)\ttotal: 10m\tremaining: 15m 20s\n",
      "395:\tlearn: 0.0222926\ttest: 0.4336743\tbest: 0.4301470 (302)\ttotal: 10m 2s\tremaining: 15m 18s\n",
      "396:\tlearn: 0.0222267\ttest: 0.4336591\tbest: 0.4301470 (302)\ttotal: 10m 3s\tremaining: 15m 17s\n",
      "397:\tlearn: 0.0221774\ttest: 0.4333380\tbest: 0.4301470 (302)\ttotal: 10m 5s\tremaining: 15m 15s\n",
      "398:\tlearn: 0.0220635\ttest: 0.4334850\tbest: 0.4301470 (302)\ttotal: 10m 7s\tremaining: 15m 14s\n",
      "399:\tlearn: 0.0219437\ttest: 0.4332217\tbest: 0.4301470 (302)\ttotal: 10m 8s\tremaining: 15m 12s\n",
      "400:\tlearn: 0.0218332\ttest: 0.4331096\tbest: 0.4301470 (302)\ttotal: 10m 10s\tremaining: 15m 11s\n",
      "401:\tlearn: 0.0217519\ttest: 0.4328891\tbest: 0.4301470 (302)\ttotal: 10m 11s\tremaining: 15m 9s\n",
      "402:\tlearn: 0.0216426\ttest: 0.4332321\tbest: 0.4301470 (302)\ttotal: 10m 13s\tremaining: 15m 8s\n",
      "403:\tlearn: 0.0215094\ttest: 0.4331135\tbest: 0.4301470 (302)\ttotal: 10m 14s\tremaining: 15m 7s\n",
      "404:\tlearn: 0.0214090\ttest: 0.4326716\tbest: 0.4301470 (302)\ttotal: 10m 16s\tremaining: 15m 5s\n",
      "405:\tlearn: 0.0213456\ttest: 0.4327524\tbest: 0.4301470 (302)\ttotal: 10m 17s\tremaining: 15m 4s\n",
      "406:\tlearn: 0.0212531\ttest: 0.4324996\tbest: 0.4301470 (302)\ttotal: 10m 19s\tremaining: 15m 2s\n",
      "407:\tlearn: 0.0211353\ttest: 0.4323721\tbest: 0.4301470 (302)\ttotal: 10m 21s\tremaining: 15m 1s\n",
      "408:\tlearn: 0.0210156\ttest: 0.4324690\tbest: 0.4301470 (302)\ttotal: 10m 22s\tremaining: 14m 59s\n",
      "409:\tlearn: 0.0208887\ttest: 0.4328400\tbest: 0.4301470 (302)\ttotal: 10m 24s\tremaining: 14m 58s\n",
      "410:\tlearn: 0.0207777\ttest: 0.4331050\tbest: 0.4301470 (302)\ttotal: 10m 25s\tremaining: 14m 56s\n",
      "411:\tlearn: 0.0207403\ttest: 0.4331462\tbest: 0.4301470 (302)\ttotal: 10m 27s\tremaining: 14m 55s\n",
      "412:\tlearn: 0.0206435\ttest: 0.4330885\tbest: 0.4301470 (302)\ttotal: 10m 29s\tremaining: 14m 54s\n",
      "413:\tlearn: 0.0205405\ttest: 0.4331194\tbest: 0.4301470 (302)\ttotal: 10m 30s\tremaining: 14m 52s\n",
      "414:\tlearn: 0.0204622\ttest: 0.4333702\tbest: 0.4301470 (302)\ttotal: 10m 32s\tremaining: 14m 51s\n",
      "415:\tlearn: 0.0203544\ttest: 0.4334191\tbest: 0.4301470 (302)\ttotal: 10m 33s\tremaining: 14m 49s\n",
      "416:\tlearn: 0.0202721\ttest: 0.4333736\tbest: 0.4301470 (302)\ttotal: 10m 35s\tremaining: 14m 48s\n",
      "417:\tlearn: 0.0202136\ttest: 0.4331657\tbest: 0.4301470 (302)\ttotal: 10m 36s\tremaining: 14m 46s\n",
      "418:\tlearn: 0.0201625\ttest: 0.4332130\tbest: 0.4301470 (302)\ttotal: 10m 38s\tremaining: 14m 45s\n",
      "419:\tlearn: 0.0200908\ttest: 0.4332293\tbest: 0.4301470 (302)\ttotal: 10m 39s\tremaining: 14m 43s\n",
      "420:\tlearn: 0.0199936\ttest: 0.4329557\tbest: 0.4301470 (302)\ttotal: 10m 41s\tremaining: 14m 42s\n",
      "421:\tlearn: 0.0199073\ttest: 0.4329355\tbest: 0.4301470 (302)\ttotal: 10m 43s\tremaining: 14m 40s\n",
      "422:\tlearn: 0.0198421\ttest: 0.4327492\tbest: 0.4301470 (302)\ttotal: 10m 44s\tremaining: 14m 39s\n",
      "423:\tlearn: 0.0197482\ttest: 0.4326030\tbest: 0.4301470 (302)\ttotal: 10m 46s\tremaining: 14m 37s\n",
      "424:\tlearn: 0.0196703\ttest: 0.4328148\tbest: 0.4301470 (302)\ttotal: 10m 47s\tremaining: 14m 36s\n",
      "425:\tlearn: 0.0195759\ttest: 0.4328760\tbest: 0.4301470 (302)\ttotal: 10m 49s\tremaining: 14m 34s\n",
      "426:\tlearn: 0.0195238\ttest: 0.4334278\tbest: 0.4301470 (302)\ttotal: 10m 50s\tremaining: 14m 33s\n",
      "427:\tlearn: 0.0194499\ttest: 0.4331403\tbest: 0.4301470 (302)\ttotal: 10m 52s\tremaining: 14m 31s\n",
      "428:\tlearn: 0.0193876\ttest: 0.4332004\tbest: 0.4301470 (302)\ttotal: 10m 53s\tremaining: 14m 30s\n",
      "429:\tlearn: 0.0193305\ttest: 0.4333442\tbest: 0.4301470 (302)\ttotal: 10m 55s\tremaining: 14m 28s\n",
      "430:\tlearn: 0.0192920\ttest: 0.4334667\tbest: 0.4301470 (302)\ttotal: 10m 57s\tremaining: 14m 27s\n",
      "431:\tlearn: 0.0192285\ttest: 0.4334384\tbest: 0.4301470 (302)\ttotal: 10m 58s\tremaining: 14m 25s\n",
      "432:\tlearn: 0.0191618\ttest: 0.4337231\tbest: 0.4301470 (302)\ttotal: 11m\tremaining: 14m 24s\n",
      "433:\tlearn: 0.0191072\ttest: 0.4336138\tbest: 0.4301470 (302)\ttotal: 11m 1s\tremaining: 14m 22s\n",
      "434:\tlearn: 0.0190503\ttest: 0.4333984\tbest: 0.4301470 (302)\ttotal: 11m 3s\tremaining: 14m 21s\n",
      "435:\tlearn: 0.0189872\ttest: 0.4336812\tbest: 0.4301470 (302)\ttotal: 11m 4s\tremaining: 14m 19s\n",
      "436:\tlearn: 0.0189003\ttest: 0.4335058\tbest: 0.4301470 (302)\ttotal: 11m 6s\tremaining: 14m 18s\n",
      "437:\tlearn: 0.0188518\ttest: 0.4332415\tbest: 0.4301470 (302)\ttotal: 11m 7s\tremaining: 14m 17s\n",
      "438:\tlearn: 0.0187969\ttest: 0.4336719\tbest: 0.4301470 (302)\ttotal: 11m 9s\tremaining: 14m 15s\n",
      "439:\tlearn: 0.0187341\ttest: 0.4333935\tbest: 0.4301470 (302)\ttotal: 11m 11s\tremaining: 14m 14s\n",
      "440:\tlearn: 0.0186932\ttest: 0.4334077\tbest: 0.4301470 (302)\ttotal: 11m 12s\tremaining: 14m 12s\n",
      "441:\tlearn: 0.0186004\ttest: 0.4337461\tbest: 0.4301470 (302)\ttotal: 11m 14s\tremaining: 14m 11s\n",
      "442:\tlearn: 0.0185460\ttest: 0.4329034\tbest: 0.4301470 (302)\ttotal: 11m 15s\tremaining: 14m 9s\n",
      "443:\tlearn: 0.0184905\ttest: 0.4330653\tbest: 0.4301470 (302)\ttotal: 11m 17s\tremaining: 14m 8s\n",
      "444:\tlearn: 0.0184272\ttest: 0.4328445\tbest: 0.4301470 (302)\ttotal: 11m 18s\tremaining: 14m 6s\n",
      "445:\tlearn: 0.0183687\ttest: 0.4330226\tbest: 0.4301470 (302)\ttotal: 11m 20s\tremaining: 14m 4s\n",
      "446:\tlearn: 0.0183030\ttest: 0.4330651\tbest: 0.4301470 (302)\ttotal: 11m 21s\tremaining: 14m 3s\n",
      "447:\tlearn: 0.0182431\ttest: 0.4334150\tbest: 0.4301470 (302)\ttotal: 11m 22s\tremaining: 14m 1s\n",
      "448:\tlearn: 0.0181947\ttest: 0.4333233\tbest: 0.4301470 (302)\ttotal: 11m 24s\tremaining: 13m 59s\n",
      "449:\tlearn: 0.0181286\ttest: 0.4330595\tbest: 0.4301470 (302)\ttotal: 11m 25s\tremaining: 13m 58s\n",
      "450:\tlearn: 0.0180745\ttest: 0.4332135\tbest: 0.4301470 (302)\ttotal: 11m 27s\tremaining: 13m 56s\n",
      "451:\tlearn: 0.0179782\ttest: 0.4334838\tbest: 0.4301470 (302)\ttotal: 11m 28s\tremaining: 13m 54s\n",
      "452:\tlearn: 0.0179089\ttest: 0.4335425\tbest: 0.4301470 (302)\ttotal: 11m 30s\tremaining: 13m 53s\n",
      "453:\tlearn: 0.0178423\ttest: 0.4336494\tbest: 0.4301470 (302)\ttotal: 11m 31s\tremaining: 13m 51s\n",
      "454:\tlearn: 0.0178016\ttest: 0.4335484\tbest: 0.4301470 (302)\ttotal: 11m 32s\tremaining: 13m 49s\n",
      "455:\tlearn: 0.0177340\ttest: 0.4333318\tbest: 0.4301470 (302)\ttotal: 11m 34s\tremaining: 13m 48s\n",
      "456:\tlearn: 0.0176617\ttest: 0.4331596\tbest: 0.4301470 (302)\ttotal: 11m 35s\tremaining: 13m 46s\n",
      "457:\tlearn: 0.0176194\ttest: 0.4332577\tbest: 0.4301470 (302)\ttotal: 11m 37s\tremaining: 13m 44s\n",
      "458:\tlearn: 0.0175606\ttest: 0.4331524\tbest: 0.4301470 (302)\ttotal: 11m 38s\tremaining: 13m 43s\n",
      "459:\tlearn: 0.0174712\ttest: 0.4336347\tbest: 0.4301470 (302)\ttotal: 11m 39s\tremaining: 13m 41s\n",
      "460:\tlearn: 0.0174314\ttest: 0.4333314\tbest: 0.4301470 (302)\ttotal: 11m 41s\tremaining: 13m 39s\n",
      "461:\tlearn: 0.0173805\ttest: 0.4332946\tbest: 0.4301470 (302)\ttotal: 11m 42s\tremaining: 13m 38s\n",
      "462:\tlearn: 0.0173184\ttest: 0.4332028\tbest: 0.4301470 (302)\ttotal: 11m 44s\tremaining: 13m 36s\n",
      "463:\tlearn: 0.0172598\ttest: 0.4333600\tbest: 0.4301470 (302)\ttotal: 11m 45s\tremaining: 13m 35s\n",
      "464:\tlearn: 0.0171739\ttest: 0.4333862\tbest: 0.4301470 (302)\ttotal: 11m 47s\tremaining: 13m 33s\n",
      "465:\tlearn: 0.0171197\ttest: 0.4336412\tbest: 0.4301470 (302)\ttotal: 11m 48s\tremaining: 13m 32s\n",
      "466:\tlearn: 0.0170744\ttest: 0.4337351\tbest: 0.4301470 (302)\ttotal: 11m 50s\tremaining: 13m 30s\n",
      "467:\tlearn: 0.0169921\ttest: 0.4339895\tbest: 0.4301470 (302)\ttotal: 11m 51s\tremaining: 13m 29s\n",
      "468:\tlearn: 0.0169353\ttest: 0.4338726\tbest: 0.4301470 (302)\ttotal: 11m 53s\tremaining: 13m 27s\n",
      "469:\tlearn: 0.0168873\ttest: 0.4344665\tbest: 0.4301470 (302)\ttotal: 11m 54s\tremaining: 13m 25s\n",
      "470:\tlearn: 0.0168343\ttest: 0.4345601\tbest: 0.4301470 (302)\ttotal: 11m 56s\tremaining: 13m 24s\n",
      "471:\tlearn: 0.0167950\ttest: 0.4345754\tbest: 0.4301470 (302)\ttotal: 11m 57s\tremaining: 13m 22s\n",
      "472:\tlearn: 0.0167415\ttest: 0.4346825\tbest: 0.4301470 (302)\ttotal: 11m 59s\tremaining: 13m 21s\n",
      "473:\tlearn: 0.0167109\ttest: 0.4346926\tbest: 0.4301470 (302)\ttotal: 12m\tremaining: 13m 19s\n",
      "474:\tlearn: 0.0166744\ttest: 0.4348365\tbest: 0.4301470 (302)\ttotal: 12m 2s\tremaining: 13m 18s\n",
      "475:\tlearn: 0.0166064\ttest: 0.4348463\tbest: 0.4301470 (302)\ttotal: 12m 3s\tremaining: 13m 16s\n",
      "476:\tlearn: 0.0165507\ttest: 0.4351072\tbest: 0.4301470 (302)\ttotal: 12m 5s\tremaining: 13m 15s\n",
      "477:\tlearn: 0.0165059\ttest: 0.4351662\tbest: 0.4301470 (302)\ttotal: 12m 6s\tremaining: 13m 13s\n",
      "478:\tlearn: 0.0164626\ttest: 0.4352112\tbest: 0.4301470 (302)\ttotal: 12m 8s\tremaining: 13m 12s\n",
      "479:\tlearn: 0.0164030\ttest: 0.4356138\tbest: 0.4301470 (302)\ttotal: 12m 10s\tremaining: 13m 10s\n",
      "480:\tlearn: 0.0163097\ttest: 0.4357729\tbest: 0.4301470 (302)\ttotal: 12m 11s\tremaining: 13m 9s\n",
      "481:\tlearn: 0.0162381\ttest: 0.4359069\tbest: 0.4301470 (302)\ttotal: 12m 13s\tremaining: 13m 7s\n",
      "482:\tlearn: 0.0161768\ttest: 0.4360441\tbest: 0.4301470 (302)\ttotal: 12m 14s\tremaining: 13m 6s\n",
      "483:\tlearn: 0.0161348\ttest: 0.4359094\tbest: 0.4301470 (302)\ttotal: 12m 16s\tremaining: 13m 4s\n",
      "484:\tlearn: 0.0160639\ttest: 0.4354556\tbest: 0.4301470 (302)\ttotal: 12m 17s\tremaining: 13m 3s\n",
      "485:\tlearn: 0.0160165\ttest: 0.4354928\tbest: 0.4301470 (302)\ttotal: 12m 19s\tremaining: 13m 2s\n",
      "486:\tlearn: 0.0159671\ttest: 0.4356119\tbest: 0.4301470 (302)\ttotal: 12m 21s\tremaining: 13m\n",
      "487:\tlearn: 0.0158892\ttest: 0.4355899\tbest: 0.4301470 (302)\ttotal: 12m 22s\tremaining: 12m 59s\n",
      "488:\tlearn: 0.0158082\ttest: 0.4356797\tbest: 0.4301470 (302)\ttotal: 12m 24s\tremaining: 12m 57s\n",
      "489:\tlearn: 0.0157687\ttest: 0.4361167\tbest: 0.4301470 (302)\ttotal: 12m 25s\tremaining: 12m 56s\n",
      "490:\tlearn: 0.0156968\ttest: 0.4359709\tbest: 0.4301470 (302)\ttotal: 12m 27s\tremaining: 12m 54s\n",
      "491:\tlearn: 0.0156311\ttest: 0.4357969\tbest: 0.4301470 (302)\ttotal: 12m 28s\tremaining: 12m 53s\n",
      "492:\tlearn: 0.0155914\ttest: 0.4358008\tbest: 0.4301470 (302)\ttotal: 12m 30s\tremaining: 12m 51s\n",
      "493:\tlearn: 0.0155547\ttest: 0.4359046\tbest: 0.4301470 (302)\ttotal: 12m 31s\tremaining: 12m 49s\n",
      "494:\tlearn: 0.0155275\ttest: 0.4360163\tbest: 0.4301470 (302)\ttotal: 12m 32s\tremaining: 12m 48s\n",
      "495:\tlearn: 0.0155017\ttest: 0.4362069\tbest: 0.4301470 (302)\ttotal: 12m 34s\tremaining: 12m 46s\n",
      "496:\tlearn: 0.0154702\ttest: 0.4361138\tbest: 0.4301470 (302)\ttotal: 12m 35s\tremaining: 12m 44s\n",
      "497:\tlearn: 0.0154269\ttest: 0.4366903\tbest: 0.4301470 (302)\ttotal: 12m 37s\tremaining: 12m 43s\n",
      "498:\tlearn: 0.0153525\ttest: 0.4361827\tbest: 0.4301470 (302)\ttotal: 12m 38s\tremaining: 12m 41s\n",
      "499:\tlearn: 0.0153161\ttest: 0.4362489\tbest: 0.4301470 (302)\ttotal: 12m 40s\tremaining: 12m 40s\n",
      "500:\tlearn: 0.0152651\ttest: 0.4366107\tbest: 0.4301470 (302)\ttotal: 12m 42s\tremaining: 12m 38s\n",
      "501:\tlearn: 0.0152043\ttest: 0.4366979\tbest: 0.4301470 (302)\ttotal: 12m 43s\tremaining: 12m 37s\n",
      "502:\tlearn: 0.0151329\ttest: 0.4368547\tbest: 0.4301470 (302)\ttotal: 12m 45s\tremaining: 12m 36s\n",
      "503:\tlearn: 0.0150606\ttest: 0.4372676\tbest: 0.4301470 (302)\ttotal: 12m 46s\tremaining: 12m 34s\n",
      "504:\tlearn: 0.0150287\ttest: 0.4369868\tbest: 0.4301470 (302)\ttotal: 12m 48s\tremaining: 12m 33s\n",
      "505:\tlearn: 0.0149949\ttest: 0.4368544\tbest: 0.4301470 (302)\ttotal: 12m 49s\tremaining: 12m 31s\n",
      "506:\tlearn: 0.0149580\ttest: 0.4370993\tbest: 0.4301470 (302)\ttotal: 12m 51s\tremaining: 12m 30s\n",
      "507:\tlearn: 0.0149127\ttest: 0.4370084\tbest: 0.4301470 (302)\ttotal: 12m 53s\tremaining: 12m 28s\n",
      "508:\tlearn: 0.0148655\ttest: 0.4373774\tbest: 0.4301470 (302)\ttotal: 12m 54s\tremaining: 12m 27s\n",
      "509:\tlearn: 0.0148069\ttest: 0.4370805\tbest: 0.4301470 (302)\ttotal: 12m 56s\tremaining: 12m 25s\n",
      "510:\tlearn: 0.0147525\ttest: 0.4368088\tbest: 0.4301470 (302)\ttotal: 12m 57s\tremaining: 12m 24s\n",
      "511:\tlearn: 0.0147122\ttest: 0.4370062\tbest: 0.4301470 (302)\ttotal: 12m 59s\tremaining: 12m 22s\n",
      "512:\tlearn: 0.0146267\ttest: 0.4367084\tbest: 0.4301470 (302)\ttotal: 13m\tremaining: 12m 21s\n",
      "513:\tlearn: 0.0145853\ttest: 0.4366184\tbest: 0.4301470 (302)\ttotal: 13m 2s\tremaining: 12m 19s\n",
      "514:\tlearn: 0.0145304\ttest: 0.4361062\tbest: 0.4301470 (302)\ttotal: 13m 3s\tremaining: 12m 18s\n",
      "515:\tlearn: 0.0144863\ttest: 0.4365809\tbest: 0.4301470 (302)\ttotal: 13m 5s\tremaining: 12m 16s\n",
      "516:\tlearn: 0.0144566\ttest: 0.4362677\tbest: 0.4301470 (302)\ttotal: 13m 6s\tremaining: 12m 14s\n",
      "517:\tlearn: 0.0144170\ttest: 0.4362158\tbest: 0.4301470 (302)\ttotal: 13m 8s\tremaining: 12m 13s\n",
      "518:\tlearn: 0.0143799\ttest: 0.4363546\tbest: 0.4301470 (302)\ttotal: 13m 9s\tremaining: 12m 11s\n",
      "519:\tlearn: 0.0143397\ttest: 0.4366894\tbest: 0.4301470 (302)\ttotal: 13m 11s\tremaining: 12m 10s\n",
      "520:\tlearn: 0.0142838\ttest: 0.4365326\tbest: 0.4301470 (302)\ttotal: 13m 12s\tremaining: 12m 8s\n",
      "521:\tlearn: 0.0142279\ttest: 0.4363668\tbest: 0.4301470 (302)\ttotal: 13m 14s\tremaining: 12m 7s\n",
      "522:\tlearn: 0.0141770\ttest: 0.4361915\tbest: 0.4301470 (302)\ttotal: 13m 15s\tremaining: 12m 5s\n",
      "523:\tlearn: 0.0141097\ttest: 0.4362524\tbest: 0.4301470 (302)\ttotal: 13m 17s\tremaining: 12m 4s\n",
      "524:\tlearn: 0.0140627\ttest: 0.4364646\tbest: 0.4301470 (302)\ttotal: 13m 19s\tremaining: 12m 2s\n",
      "525:\tlearn: 0.0140226\ttest: 0.4364996\tbest: 0.4301470 (302)\ttotal: 13m 20s\tremaining: 12m 1s\n",
      "526:\tlearn: 0.0139712\ttest: 0.4362531\tbest: 0.4301470 (302)\ttotal: 13m 22s\tremaining: 12m\n",
      "527:\tlearn: 0.0139252\ttest: 0.4362297\tbest: 0.4301470 (302)\ttotal: 13m 23s\tremaining: 11m 58s\n",
      "528:\tlearn: 0.0138640\ttest: 0.4363019\tbest: 0.4301470 (302)\ttotal: 13m 25s\tremaining: 11m 56s\n",
      "529:\tlearn: 0.0138188\ttest: 0.4361603\tbest: 0.4301470 (302)\ttotal: 13m 26s\tremaining: 11m 55s\n",
      "530:\tlearn: 0.0137587\ttest: 0.4360459\tbest: 0.4301470 (302)\ttotal: 13m 28s\tremaining: 11m 53s\n",
      "531:\tlearn: 0.0137077\ttest: 0.4362369\tbest: 0.4301470 (302)\ttotal: 13m 29s\tremaining: 11m 52s\n",
      "532:\tlearn: 0.0136544\ttest: 0.4358601\tbest: 0.4301470 (302)\ttotal: 13m 30s\tremaining: 11m 50s\n",
      "533:\tlearn: 0.0136266\ttest: 0.4358248\tbest: 0.4301470 (302)\ttotal: 13m 32s\tremaining: 11m 48s\n",
      "534:\tlearn: 0.0135894\ttest: 0.4357392\tbest: 0.4301470 (302)\ttotal: 13m 33s\tremaining: 11m 47s\n",
      "535:\tlearn: 0.0135481\ttest: 0.4356210\tbest: 0.4301470 (302)\ttotal: 13m 35s\tremaining: 11m 45s\n",
      "536:\tlearn: 0.0135060\ttest: 0.4359057\tbest: 0.4301470 (302)\ttotal: 13m 36s\tremaining: 11m 44s\n",
      "537:\tlearn: 0.0134657\ttest: 0.4360720\tbest: 0.4301470 (302)\ttotal: 13m 38s\tremaining: 11m 42s\n",
      "538:\tlearn: 0.0134267\ttest: 0.4362925\tbest: 0.4301470 (302)\ttotal: 13m 39s\tremaining: 11m 41s\n",
      "539:\tlearn: 0.0133877\ttest: 0.4369191\tbest: 0.4301470 (302)\ttotal: 13m 41s\tremaining: 11m 39s\n",
      "540:\tlearn: 0.0133597\ttest: 0.4367702\tbest: 0.4301470 (302)\ttotal: 13m 42s\tremaining: 11m 37s\n",
      "541:\tlearn: 0.0132991\ttest: 0.4378762\tbest: 0.4301470 (302)\ttotal: 13m 43s\tremaining: 11m 36s\n",
      "542:\tlearn: 0.0132523\ttest: 0.4378672\tbest: 0.4301470 (302)\ttotal: 13m 45s\tremaining: 11m 34s\n",
      "543:\tlearn: 0.0132176\ttest: 0.4383898\tbest: 0.4301470 (302)\ttotal: 13m 46s\tremaining: 11m 33s\n",
      "544:\tlearn: 0.0131752\ttest: 0.4382612\tbest: 0.4301470 (302)\ttotal: 13m 48s\tremaining: 11m 31s\n",
      "545:\tlearn: 0.0131470\ttest: 0.4385047\tbest: 0.4301470 (302)\ttotal: 13m 49s\tremaining: 11m 29s\n",
      "546:\tlearn: 0.0131119\ttest: 0.4384503\tbest: 0.4301470 (302)\ttotal: 13m 50s\tremaining: 11m 28s\n",
      "547:\tlearn: 0.0130901\ttest: 0.4383291\tbest: 0.4301470 (302)\ttotal: 13m 52s\tremaining: 11m 26s\n",
      "548:\tlearn: 0.0130421\ttest: 0.4384074\tbest: 0.4301470 (302)\ttotal: 13m 53s\tremaining: 11m 24s\n",
      "549:\tlearn: 0.0130070\ttest: 0.4385048\tbest: 0.4301470 (302)\ttotal: 13m 55s\tremaining: 11m 23s\n",
      "550:\tlearn: 0.0129521\ttest: 0.4388170\tbest: 0.4301470 (302)\ttotal: 13m 56s\tremaining: 11m 21s\n",
      "551:\tlearn: 0.0129140\ttest: 0.4389207\tbest: 0.4301470 (302)\ttotal: 13m 58s\tremaining: 11m 20s\n",
      "552:\tlearn: 0.0128884\ttest: 0.4390500\tbest: 0.4301470 (302)\ttotal: 13m 59s\tremaining: 11m 18s\n",
      "553:\tlearn: 0.0128550\ttest: 0.4388743\tbest: 0.4301470 (302)\ttotal: 14m\tremaining: 11m 16s\n",
      "554:\tlearn: 0.0128060\ttest: 0.4389392\tbest: 0.4301470 (302)\ttotal: 14m 2s\tremaining: 11m 15s\n",
      "555:\tlearn: 0.0127804\ttest: 0.4387266\tbest: 0.4301470 (302)\ttotal: 14m 3s\tremaining: 11m 13s\n",
      "556:\tlearn: 0.0127398\ttest: 0.4389907\tbest: 0.4301470 (302)\ttotal: 14m 5s\tremaining: 11m 12s\n",
      "557:\tlearn: 0.0127023\ttest: 0.4391379\tbest: 0.4301470 (302)\ttotal: 14m 6s\tremaining: 11m 10s\n",
      "558:\tlearn: 0.0126802\ttest: 0.4391681\tbest: 0.4301470 (302)\ttotal: 14m 8s\tremaining: 11m 9s\n",
      "559:\tlearn: 0.0126387\ttest: 0.4390449\tbest: 0.4301470 (302)\ttotal: 14m 9s\tremaining: 11m 7s\n",
      "560:\tlearn: 0.0125998\ttest: 0.4390057\tbest: 0.4301470 (302)\ttotal: 14m 10s\tremaining: 11m 5s\n",
      "561:\tlearn: 0.0125719\ttest: 0.4389206\tbest: 0.4301470 (302)\ttotal: 14m 12s\tremaining: 11m 4s\n",
      "562:\tlearn: 0.0125212\ttest: 0.4388727\tbest: 0.4301470 (302)\ttotal: 14m 13s\tremaining: 11m 2s\n",
      "563:\tlearn: 0.0124973\ttest: 0.4383876\tbest: 0.4301470 (302)\ttotal: 14m 15s\tremaining: 11m 1s\n",
      "564:\tlearn: 0.0124674\ttest: 0.4385408\tbest: 0.4301470 (302)\ttotal: 14m 16s\tremaining: 10m 59s\n",
      "565:\tlearn: 0.0124495\ttest: 0.4383467\tbest: 0.4301470 (302)\ttotal: 14m 17s\tremaining: 10m 57s\n",
      "566:\tlearn: 0.0124076\ttest: 0.4382077\tbest: 0.4301470 (302)\ttotal: 14m 19s\tremaining: 10m 56s\n",
      "567:\tlearn: 0.0123878\ttest: 0.4382546\tbest: 0.4301470 (302)\ttotal: 14m 20s\tremaining: 10m 54s\n",
      "568:\tlearn: 0.0123431\ttest: 0.4379340\tbest: 0.4301470 (302)\ttotal: 14m 22s\tremaining: 10m 53s\n",
      "569:\tlearn: 0.0123056\ttest: 0.4382968\tbest: 0.4301470 (302)\ttotal: 14m 23s\tremaining: 10m 51s\n",
      "570:\tlearn: 0.0122703\ttest: 0.4378949\tbest: 0.4301470 (302)\ttotal: 14m 24s\tremaining: 10m 49s\n",
      "571:\tlearn: 0.0122202\ttest: 0.4383572\tbest: 0.4301470 (302)\ttotal: 14m 26s\tremaining: 10m 48s\n",
      "572:\tlearn: 0.0121853\ttest: 0.4385067\tbest: 0.4301470 (302)\ttotal: 14m 27s\tremaining: 10m 46s\n",
      "573:\tlearn: 0.0121527\ttest: 0.4383454\tbest: 0.4301470 (302)\ttotal: 14m 29s\tremaining: 10m 45s\n",
      "574:\tlearn: 0.0121293\ttest: 0.4384251\tbest: 0.4301470 (302)\ttotal: 14m 30s\tremaining: 10m 43s\n",
      "575:\tlearn: 0.0121013\ttest: 0.4382413\tbest: 0.4301470 (302)\ttotal: 14m 31s\tremaining: 10m 41s\n",
      "576:\tlearn: 0.0120627\ttest: 0.4384135\tbest: 0.4301470 (302)\ttotal: 14m 33s\tremaining: 10m 40s\n",
      "577:\tlearn: 0.0120316\ttest: 0.4378031\tbest: 0.4301470 (302)\ttotal: 14m 34s\tremaining: 10m 38s\n",
      "578:\tlearn: 0.0120081\ttest: 0.4378630\tbest: 0.4301470 (302)\ttotal: 14m 36s\tremaining: 10m 37s\n",
      "579:\tlearn: 0.0119920\ttest: 0.4379509\tbest: 0.4301470 (302)\ttotal: 14m 37s\tremaining: 10m 35s\n",
      "580:\tlearn: 0.0119532\ttest: 0.4380147\tbest: 0.4301470 (302)\ttotal: 14m 39s\tremaining: 10m 33s\n",
      "581:\tlearn: 0.0119306\ttest: 0.4378219\tbest: 0.4301470 (302)\ttotal: 14m 40s\tremaining: 10m 32s\n",
      "582:\tlearn: 0.0118838\ttest: 0.4380135\tbest: 0.4301470 (302)\ttotal: 14m 41s\tremaining: 10m 30s\n",
      "583:\tlearn: 0.0118440\ttest: 0.4377350\tbest: 0.4301470 (302)\ttotal: 14m 43s\tremaining: 10m 29s\n",
      "584:\tlearn: 0.0118177\ttest: 0.4375985\tbest: 0.4301470 (302)\ttotal: 14m 44s\tremaining: 10m 27s\n",
      "585:\tlearn: 0.0117747\ttest: 0.4380419\tbest: 0.4301470 (302)\ttotal: 14m 46s\tremaining: 10m 25s\n",
      "586:\tlearn: 0.0117328\ttest: 0.4379087\tbest: 0.4301470 (302)\ttotal: 14m 47s\tremaining: 10m 24s\n",
      "587:\tlearn: 0.0117078\ttest: 0.4374795\tbest: 0.4301470 (302)\ttotal: 14m 48s\tremaining: 10m 22s\n",
      "588:\tlearn: 0.0116639\ttest: 0.4374031\tbest: 0.4301470 (302)\ttotal: 14m 50s\tremaining: 10m 21s\n",
      "589:\tlearn: 0.0116175\ttest: 0.4371924\tbest: 0.4301470 (302)\ttotal: 14m 51s\tremaining: 10m 19s\n",
      "590:\tlearn: 0.0115837\ttest: 0.4373895\tbest: 0.4301470 (302)\ttotal: 14m 52s\tremaining: 10m 17s\n",
      "591:\tlearn: 0.0115570\ttest: 0.4372612\tbest: 0.4301470 (302)\ttotal: 14m 54s\tremaining: 10m 16s\n",
      "592:\tlearn: 0.0115286\ttest: 0.4373321\tbest: 0.4301470 (302)\ttotal: 14m 55s\tremaining: 10m 14s\n",
      "593:\tlearn: 0.0115048\ttest: 0.4372165\tbest: 0.4301470 (302)\ttotal: 14m 57s\tremaining: 10m 13s\n",
      "594:\tlearn: 0.0114581\ttest: 0.4373716\tbest: 0.4301470 (302)\ttotal: 14m 58s\tremaining: 10m 11s\n",
      "595:\tlearn: 0.0114300\ttest: 0.4377807\tbest: 0.4301470 (302)\ttotal: 14m 59s\tremaining: 10m 10s\n",
      "596:\tlearn: 0.0113895\ttest: 0.4377468\tbest: 0.4301470 (302)\ttotal: 15m 1s\tremaining: 10m 8s\n",
      "597:\tlearn: 0.0113705\ttest: 0.4376221\tbest: 0.4301470 (302)\ttotal: 15m 2s\tremaining: 10m 6s\n",
      "598:\tlearn: 0.0113281\ttest: 0.4377204\tbest: 0.4301470 (302)\ttotal: 15m 4s\tremaining: 10m 5s\n",
      "599:\tlearn: 0.0112899\ttest: 0.4380466\tbest: 0.4301470 (302)\ttotal: 15m 5s\tremaining: 10m 3s\n",
      "600:\tlearn: 0.0112567\ttest: 0.4382617\tbest: 0.4301470 (302)\ttotal: 15m 6s\tremaining: 10m 2s\n",
      "601:\tlearn: 0.0112433\ttest: 0.4382570\tbest: 0.4301470 (302)\ttotal: 15m 8s\tremaining: 10m\n",
      "602:\tlearn: 0.0112113\ttest: 0.4380260\tbest: 0.4301470 (302)\ttotal: 15m 9s\tremaining: 9m 58s\n",
      "603:\tlearn: 0.0111938\ttest: 0.4384379\tbest: 0.4301470 (302)\ttotal: 15m 11s\tremaining: 9m 57s\n",
      "604:\tlearn: 0.0111654\ttest: 0.4386957\tbest: 0.4301470 (302)\ttotal: 15m 12s\tremaining: 9m 55s\n",
      "605:\tlearn: 0.0111503\ttest: 0.4389289\tbest: 0.4301470 (302)\ttotal: 15m 13s\tremaining: 9m 54s\n",
      "606:\tlearn: 0.0111345\ttest: 0.4389630\tbest: 0.4301470 (302)\ttotal: 15m 15s\tremaining: 9m 52s\n",
      "607:\tlearn: 0.0111011\ttest: 0.4390674\tbest: 0.4301470 (302)\ttotal: 15m 16s\tremaining: 9m 51s\n",
      "608:\tlearn: 0.0110718\ttest: 0.4392007\tbest: 0.4301470 (302)\ttotal: 15m 18s\tremaining: 9m 49s\n",
      "609:\tlearn: 0.0110366\ttest: 0.4395209\tbest: 0.4301470 (302)\ttotal: 15m 19s\tremaining: 9m 47s\n",
      "610:\tlearn: 0.0109979\ttest: 0.4394811\tbest: 0.4301470 (302)\ttotal: 15m 20s\tremaining: 9m 46s\n",
      "611:\tlearn: 0.0109753\ttest: 0.4395267\tbest: 0.4301470 (302)\ttotal: 15m 22s\tremaining: 9m 44s\n",
      "612:\tlearn: 0.0109375\ttest: 0.4396966\tbest: 0.4301470 (302)\ttotal: 15m 23s\tremaining: 9m 43s\n",
      "613:\tlearn: 0.0109017\ttest: 0.4396381\tbest: 0.4301470 (302)\ttotal: 15m 25s\tremaining: 9m 41s\n",
      "614:\tlearn: 0.0108785\ttest: 0.4395696\tbest: 0.4301470 (302)\ttotal: 15m 26s\tremaining: 9m 40s\n",
      "615:\tlearn: 0.0108423\ttest: 0.4395797\tbest: 0.4301470 (302)\ttotal: 15m 28s\tremaining: 9m 38s\n",
      "616:\tlearn: 0.0108092\ttest: 0.4393439\tbest: 0.4301470 (302)\ttotal: 15m 29s\tremaining: 9m 37s\n",
      "617:\tlearn: 0.0107804\ttest: 0.4394084\tbest: 0.4301470 (302)\ttotal: 15m 31s\tremaining: 9m 35s\n",
      "618:\tlearn: 0.0107382\ttest: 0.4396847\tbest: 0.4301470 (302)\ttotal: 15m 32s\tremaining: 9m 33s\n",
      "619:\tlearn: 0.0107088\ttest: 0.4399911\tbest: 0.4301470 (302)\ttotal: 15m 33s\tremaining: 9m 32s\n",
      "620:\tlearn: 0.0106805\ttest: 0.4398542\tbest: 0.4301470 (302)\ttotal: 15m 35s\tremaining: 9m 30s\n",
      "621:\tlearn: 0.0106573\ttest: 0.4397803\tbest: 0.4301470 (302)\ttotal: 15m 36s\tremaining: 9m 29s\n",
      "622:\tlearn: 0.0106201\ttest: 0.4402342\tbest: 0.4301470 (302)\ttotal: 15m 38s\tremaining: 9m 27s\n",
      "623:\tlearn: 0.0105981\ttest: 0.4398626\tbest: 0.4301470 (302)\ttotal: 15m 39s\tremaining: 9m 26s\n",
      "624:\tlearn: 0.0105590\ttest: 0.4397981\tbest: 0.4301470 (302)\ttotal: 15m 41s\tremaining: 9m 24s\n",
      "625:\tlearn: 0.0105405\ttest: 0.4398946\tbest: 0.4301470 (302)\ttotal: 15m 42s\tremaining: 9m 23s\n",
      "626:\tlearn: 0.0105144\ttest: 0.4395523\tbest: 0.4301470 (302)\ttotal: 15m 43s\tremaining: 9m 21s\n",
      "627:\tlearn: 0.0104952\ttest: 0.4393408\tbest: 0.4301470 (302)\ttotal: 15m 45s\tremaining: 9m 19s\n",
      "628:\tlearn: 0.0104718\ttest: 0.4398073\tbest: 0.4301470 (302)\ttotal: 15m 46s\tremaining: 9m 18s\n",
      "629:\tlearn: 0.0104434\ttest: 0.4397501\tbest: 0.4301470 (302)\ttotal: 15m 48s\tremaining: 9m 16s\n",
      "630:\tlearn: 0.0104210\ttest: 0.4395136\tbest: 0.4301470 (302)\ttotal: 15m 49s\tremaining: 9m 15s\n",
      "631:\tlearn: 0.0103950\ttest: 0.4394937\tbest: 0.4301470 (302)\ttotal: 15m 50s\tremaining: 9m 13s\n",
      "632:\tlearn: 0.0103650\ttest: 0.4396514\tbest: 0.4301470 (302)\ttotal: 15m 52s\tremaining: 9m 12s\n",
      "633:\tlearn: 0.0103429\ttest: 0.4396332\tbest: 0.4301470 (302)\ttotal: 15m 53s\tremaining: 9m 10s\n",
      "634:\tlearn: 0.0103170\ttest: 0.4398059\tbest: 0.4301470 (302)\ttotal: 15m 55s\tremaining: 9m 9s\n",
      "635:\tlearn: 0.0102822\ttest: 0.4398957\tbest: 0.4301470 (302)\ttotal: 15m 56s\tremaining: 9m 7s\n",
      "636:\tlearn: 0.0102490\ttest: 0.4401331\tbest: 0.4301470 (302)\ttotal: 15m 58s\tremaining: 9m 5s\n",
      "637:\tlearn: 0.0102199\ttest: 0.4399011\tbest: 0.4301470 (302)\ttotal: 15m 59s\tremaining: 9m 4s\n",
      "638:\tlearn: 0.0101971\ttest: 0.4400822\tbest: 0.4301470 (302)\ttotal: 16m\tremaining: 9m 2s\n",
      "639:\tlearn: 0.0101787\ttest: 0.4400606\tbest: 0.4301470 (302)\ttotal: 16m 2s\tremaining: 9m 1s\n",
      "640:\tlearn: 0.0101522\ttest: 0.4401017\tbest: 0.4301470 (302)\ttotal: 16m 3s\tremaining: 8m 59s\n",
      "641:\tlearn: 0.0101285\ttest: 0.4402662\tbest: 0.4301470 (302)\ttotal: 16m 4s\tremaining: 8m 58s\n",
      "642:\tlearn: 0.0101029\ttest: 0.4402933\tbest: 0.4301470 (302)\ttotal: 16m 6s\tremaining: 8m 56s\n",
      "643:\tlearn: 0.0100844\ttest: 0.4401878\tbest: 0.4301470 (302)\ttotal: 16m 7s\tremaining: 8m 55s\n",
      "644:\tlearn: 0.0100546\ttest: 0.4403049\tbest: 0.4301470 (302)\ttotal: 16m 9s\tremaining: 8m 53s\n",
      "645:\tlearn: 0.0100257\ttest: 0.4406105\tbest: 0.4301470 (302)\ttotal: 16m 10s\tremaining: 8m 51s\n",
      "646:\tlearn: 0.0100003\ttest: 0.4399368\tbest: 0.4301470 (302)\ttotal: 16m 12s\tremaining: 8m 50s\n",
      "647:\tlearn: 0.0099649\ttest: 0.4397436\tbest: 0.4301470 (302)\ttotal: 16m 13s\tremaining: 8m 48s\n",
      "648:\tlearn: 0.0099379\ttest: 0.4399120\tbest: 0.4301470 (302)\ttotal: 16m 14s\tremaining: 8m 47s\n",
      "649:\tlearn: 0.0099165\ttest: 0.4398037\tbest: 0.4301470 (302)\ttotal: 16m 16s\tremaining: 8m 45s\n",
      "650:\tlearn: 0.0098924\ttest: 0.4393566\tbest: 0.4301470 (302)\ttotal: 16m 18s\tremaining: 8m 44s\n",
      "651:\tlearn: 0.0098759\ttest: 0.4395572\tbest: 0.4301470 (302)\ttotal: 16m 19s\tremaining: 8m 42s\n",
      "652:\tlearn: 0.0098633\ttest: 0.4391322\tbest: 0.4301470 (302)\ttotal: 16m 21s\tremaining: 8m 41s\n",
      "653:\tlearn: 0.0098476\ttest: 0.4394614\tbest: 0.4301470 (302)\ttotal: 16m 22s\tremaining: 8m 39s\n",
      "654:\tlearn: 0.0098209\ttest: 0.4396741\tbest: 0.4301470 (302)\ttotal: 16m 24s\tremaining: 8m 38s\n",
      "655:\tlearn: 0.0097928\ttest: 0.4396037\tbest: 0.4301470 (302)\ttotal: 16m 25s\tremaining: 8m 36s\n",
      "656:\tlearn: 0.0097740\ttest: 0.4395649\tbest: 0.4301470 (302)\ttotal: 16m 27s\tremaining: 8m 35s\n",
      "657:\tlearn: 0.0097404\ttest: 0.4396343\tbest: 0.4301470 (302)\ttotal: 16m 28s\tremaining: 8m 33s\n",
      "658:\tlearn: 0.0097128\ttest: 0.4395050\tbest: 0.4301470 (302)\ttotal: 16m 29s\tremaining: 8m 32s\n",
      "659:\tlearn: 0.0096974\ttest: 0.4395666\tbest: 0.4301470 (302)\ttotal: 16m 31s\tremaining: 8m 30s\n",
      "660:\tlearn: 0.0096815\ttest: 0.4394634\tbest: 0.4301470 (302)\ttotal: 16m 32s\tremaining: 8m 29s\n",
      "661:\tlearn: 0.0096594\ttest: 0.4397421\tbest: 0.4301470 (302)\ttotal: 16m 34s\tremaining: 8m 27s\n",
      "662:\tlearn: 0.0096385\ttest: 0.4394861\tbest: 0.4301470 (302)\ttotal: 16m 35s\tremaining: 8m 26s\n",
      "663:\tlearn: 0.0096024\ttest: 0.4393441\tbest: 0.4301470 (302)\ttotal: 16m 36s\tremaining: 8m 24s\n",
      "664:\tlearn: 0.0095761\ttest: 0.4395789\tbest: 0.4301470 (302)\ttotal: 16m 38s\tremaining: 8m 22s\n",
      "665:\tlearn: 0.0095589\ttest: 0.4394761\tbest: 0.4301470 (302)\ttotal: 16m 39s\tremaining: 8m 21s\n",
      "666:\tlearn: 0.0095401\ttest: 0.4397580\tbest: 0.4301470 (302)\ttotal: 16m 41s\tremaining: 8m 19s\n",
      "667:\tlearn: 0.0095098\ttest: 0.4402276\tbest: 0.4301470 (302)\ttotal: 16m 42s\tremaining: 8m 18s\n",
      "668:\tlearn: 0.0094922\ttest: 0.4403203\tbest: 0.4301470 (302)\ttotal: 16m 43s\tremaining: 8m 16s\n",
      "669:\tlearn: 0.0094781\ttest: 0.4404198\tbest: 0.4301470 (302)\ttotal: 16m 45s\tremaining: 8m 15s\n",
      "670:\tlearn: 0.0094488\ttest: 0.4407819\tbest: 0.4301470 (302)\ttotal: 16m 46s\tremaining: 8m 13s\n",
      "671:\tlearn: 0.0094176\ttest: 0.4412933\tbest: 0.4301470 (302)\ttotal: 16m 48s\tremaining: 8m 12s\n",
      "672:\tlearn: 0.0093924\ttest: 0.4412284\tbest: 0.4301470 (302)\ttotal: 16m 49s\tremaining: 8m 10s\n",
      "673:\tlearn: 0.0093689\ttest: 0.4415746\tbest: 0.4301470 (302)\ttotal: 16m 51s\tremaining: 8m 9s\n",
      "674:\tlearn: 0.0093493\ttest: 0.4418767\tbest: 0.4301470 (302)\ttotal: 16m 52s\tremaining: 8m 7s\n",
      "675:\tlearn: 0.0093340\ttest: 0.4423753\tbest: 0.4301470 (302)\ttotal: 16m 53s\tremaining: 8m 5s\n",
      "676:\tlearn: 0.0093235\ttest: 0.4423233\tbest: 0.4301470 (302)\ttotal: 16m 55s\tremaining: 8m 4s\n",
      "677:\tlearn: 0.0092992\ttest: 0.4424340\tbest: 0.4301470 (302)\ttotal: 16m 56s\tremaining: 8m 2s\n",
      "678:\tlearn: 0.0092721\ttest: 0.4425427\tbest: 0.4301470 (302)\ttotal: 16m 58s\tremaining: 8m 1s\n",
      "679:\tlearn: 0.0092576\ttest: 0.4426934\tbest: 0.4301470 (302)\ttotal: 16m 59s\tremaining: 7m 59s\n",
      "680:\tlearn: 0.0092427\ttest: 0.4428102\tbest: 0.4301470 (302)\ttotal: 17m\tremaining: 7m 58s\n",
      "681:\tlearn: 0.0092209\ttest: 0.4424392\tbest: 0.4301470 (302)\ttotal: 17m 2s\tremaining: 7m 56s\n",
      "682:\tlearn: 0.0091900\ttest: 0.4426828\tbest: 0.4301470 (302)\ttotal: 17m 3s\tremaining: 7m 55s\n",
      "683:\tlearn: 0.0091733\ttest: 0.4426925\tbest: 0.4301470 (302)\ttotal: 17m 5s\tremaining: 7m 53s\n",
      "684:\tlearn: 0.0091536\ttest: 0.4428187\tbest: 0.4301470 (302)\ttotal: 17m 6s\tremaining: 7m 52s\n",
      "685:\tlearn: 0.0091314\ttest: 0.4427614\tbest: 0.4301470 (302)\ttotal: 17m 8s\tremaining: 7m 50s\n",
      "686:\tlearn: 0.0091165\ttest: 0.4427376\tbest: 0.4301470 (302)\ttotal: 17m 9s\tremaining: 7m 49s\n",
      "687:\tlearn: 0.0090891\ttest: 0.4420607\tbest: 0.4301470 (302)\ttotal: 17m 10s\tremaining: 7m 47s\n",
      "688:\tlearn: 0.0090677\ttest: 0.4419834\tbest: 0.4301470 (302)\ttotal: 17m 12s\tremaining: 7m 45s\n",
      "689:\tlearn: 0.0090585\ttest: 0.4419468\tbest: 0.4301470 (302)\ttotal: 17m 13s\tremaining: 7m 44s\n",
      "690:\tlearn: 0.0090365\ttest: 0.4420212\tbest: 0.4301470 (302)\ttotal: 17m 15s\tremaining: 7m 42s\n",
      "691:\tlearn: 0.0090228\ttest: 0.4419738\tbest: 0.4301470 (302)\ttotal: 17m 16s\tremaining: 7m 41s\n",
      "692:\tlearn: 0.0090094\ttest: 0.4415850\tbest: 0.4301470 (302)\ttotal: 17m 17s\tremaining: 7m 39s\n",
      "693:\tlearn: 0.0089838\ttest: 0.4411168\tbest: 0.4301470 (302)\ttotal: 17m 19s\tremaining: 7m 38s\n",
      "694:\tlearn: 0.0089565\ttest: 0.4415751\tbest: 0.4301470 (302)\ttotal: 17m 20s\tremaining: 7m 36s\n",
      "695:\tlearn: 0.0089372\ttest: 0.4415228\tbest: 0.4301470 (302)\ttotal: 17m 22s\tremaining: 7m 35s\n",
      "696:\tlearn: 0.0089114\ttest: 0.4415565\tbest: 0.4301470 (302)\ttotal: 17m 23s\tremaining: 7m 33s\n",
      "697:\tlearn: 0.0088820\ttest: 0.4418278\tbest: 0.4301470 (302)\ttotal: 17m 24s\tremaining: 7m 32s\n",
      "698:\tlearn: 0.0088607\ttest: 0.4417411\tbest: 0.4301470 (302)\ttotal: 17m 26s\tremaining: 7m 30s\n",
      "699:\tlearn: 0.0088320\ttest: 0.4416092\tbest: 0.4301470 (302)\ttotal: 17m 27s\tremaining: 7m 29s\n",
      "700:\tlearn: 0.0088101\ttest: 0.4418289\tbest: 0.4301470 (302)\ttotal: 17m 29s\tremaining: 7m 27s\n",
      "701:\tlearn: 0.0087845\ttest: 0.4419604\tbest: 0.4301470 (302)\ttotal: 17m 30s\tremaining: 7m 25s\n",
      "702:\tlearn: 0.0087667\ttest: 0.4421797\tbest: 0.4301470 (302)\ttotal: 17m 31s\tremaining: 7m 24s\n",
      "703:\tlearn: 0.0087410\ttest: 0.4424680\tbest: 0.4301470 (302)\ttotal: 17m 33s\tremaining: 7m 22s\n",
      "704:\tlearn: 0.0087141\ttest: 0.4423756\tbest: 0.4301470 (302)\ttotal: 17m 34s\tremaining: 7m 21s\n",
      "705:\tlearn: 0.0086885\ttest: 0.4425845\tbest: 0.4301470 (302)\ttotal: 17m 36s\tremaining: 7m 19s\n",
      "706:\tlearn: 0.0086731\ttest: 0.4427390\tbest: 0.4301470 (302)\ttotal: 17m 37s\tremaining: 7m 18s\n",
      "707:\tlearn: 0.0086527\ttest: 0.4424734\tbest: 0.4301470 (302)\ttotal: 17m 39s\tremaining: 7m 16s\n",
      "708:\tlearn: 0.0086304\ttest: 0.4424364\tbest: 0.4301470 (302)\ttotal: 17m 40s\tremaining: 7m 15s\n",
      "709:\tlearn: 0.0086024\ttest: 0.4426161\tbest: 0.4301470 (302)\ttotal: 17m 41s\tremaining: 7m 13s\n",
      "710:\tlearn: 0.0085871\ttest: 0.4425616\tbest: 0.4301470 (302)\ttotal: 17m 43s\tremaining: 7m 12s\n",
      "711:\tlearn: 0.0085660\ttest: 0.4425882\tbest: 0.4301470 (302)\ttotal: 17m 44s\tremaining: 7m 10s\n",
      "712:\tlearn: 0.0085532\ttest: 0.4425287\tbest: 0.4301470 (302)\ttotal: 17m 46s\tremaining: 7m 9s\n",
      "713:\tlearn: 0.0085259\ttest: 0.4425767\tbest: 0.4301470 (302)\ttotal: 17m 47s\tremaining: 7m 7s\n",
      "714:\tlearn: 0.0085136\ttest: 0.4430158\tbest: 0.4301470 (302)\ttotal: 17m 48s\tremaining: 7m 6s\n",
      "715:\tlearn: 0.0084958\ttest: 0.4432322\tbest: 0.4301470 (302)\ttotal: 17m 50s\tremaining: 7m 4s\n",
      "716:\tlearn: 0.0084805\ttest: 0.4433933\tbest: 0.4301470 (302)\ttotal: 17m 51s\tremaining: 7m 3s\n",
      "717:\tlearn: 0.0084667\ttest: 0.4433033\tbest: 0.4301470 (302)\ttotal: 17m 53s\tremaining: 7m 1s\n",
      "718:\tlearn: 0.0084455\ttest: 0.4435652\tbest: 0.4301470 (302)\ttotal: 17m 54s\tremaining: 6m 59s\n",
      "719:\tlearn: 0.0084218\ttest: 0.4438919\tbest: 0.4301470 (302)\ttotal: 17m 55s\tremaining: 6m 58s\n",
      "720:\tlearn: 0.0083948\ttest: 0.4434166\tbest: 0.4301470 (302)\ttotal: 17m 57s\tremaining: 6m 56s\n",
      "721:\tlearn: 0.0083670\ttest: 0.4437062\tbest: 0.4301470 (302)\ttotal: 17m 58s\tremaining: 6m 55s\n",
      "722:\tlearn: 0.0083539\ttest: 0.4437006\tbest: 0.4301470 (302)\ttotal: 18m\tremaining: 6m 53s\n",
      "723:\tlearn: 0.0083377\ttest: 0.4438217\tbest: 0.4301470 (302)\ttotal: 18m 1s\tremaining: 6m 52s\n",
      "724:\tlearn: 0.0083217\ttest: 0.4433444\tbest: 0.4301470 (302)\ttotal: 18m 2s\tremaining: 6m 50s\n",
      "725:\tlearn: 0.0083042\ttest: 0.4435444\tbest: 0.4301470 (302)\ttotal: 18m 4s\tremaining: 6m 49s\n",
      "726:\tlearn: 0.0082850\ttest: 0.4434135\tbest: 0.4301470 (302)\ttotal: 18m 5s\tremaining: 6m 47s\n",
      "727:\tlearn: 0.0082581\ttest: 0.4432345\tbest: 0.4301470 (302)\ttotal: 18m 7s\tremaining: 6m 46s\n",
      "728:\tlearn: 0.0082480\ttest: 0.4433242\tbest: 0.4301470 (302)\ttotal: 18m 8s\tremaining: 6m 44s\n",
      "729:\tlearn: 0.0082301\ttest: 0.4434900\tbest: 0.4301470 (302)\ttotal: 18m 9s\tremaining: 6m 43s\n",
      "730:\tlearn: 0.0082115\ttest: 0.4436295\tbest: 0.4301470 (302)\ttotal: 18m 11s\tremaining: 6m 41s\n",
      "731:\tlearn: 0.0081961\ttest: 0.4435618\tbest: 0.4301470 (302)\ttotal: 18m 12s\tremaining: 6m 40s\n",
      "732:\tlearn: 0.0081734\ttest: 0.4439238\tbest: 0.4301470 (302)\ttotal: 18m 14s\tremaining: 6m 38s\n",
      "733:\tlearn: 0.0081579\ttest: 0.4438188\tbest: 0.4301470 (302)\ttotal: 18m 15s\tremaining: 6m 36s\n",
      "734:\tlearn: 0.0081495\ttest: 0.4438511\tbest: 0.4301470 (302)\ttotal: 18m 16s\tremaining: 6m 35s\n",
      "735:\tlearn: 0.0081300\ttest: 0.4440861\tbest: 0.4301470 (302)\ttotal: 18m 18s\tremaining: 6m 33s\n",
      "736:\tlearn: 0.0081124\ttest: 0.4441795\tbest: 0.4301470 (302)\ttotal: 18m 19s\tremaining: 6m 32s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.4301469856\n",
      "bestIteration = 302\n",
      "\n",
      "Shrink model to first 303 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7858407079646017, 0.7969087991068313)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = CatBoostClassifier(task_type='CPU', max_depth=10, od_pval=1e-3)\n",
    "gbc.fit(x_train, y_train, eval_set=(x_val, y_val))\n",
    "f1_score(y_val, gbc.predict(x_val)), roc_auc_score(y_val, gbc.predict(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(x_train), torch.tensor(y_train)), \n",
    "                                       batch_size=2048)\n",
    "val_dl = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(x_val), torch.tensor(y_val)), batch_size=2048)\n",
    "test_dl = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(x_test), torch.tensor(y_test)), batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf = nn.Sequential(\n",
    "    nn.Linear(2048, 4096), \n",
    "    nn.PReLU(),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.PReLU(),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.PReLU(),\n",
    "    nn.Linear(4096, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCELoss()\n",
    "opt = torch.optim.Adam(nn_clf.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(opt, 100, .1)\n",
    "save_path = 'avg_pm_mlp.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: train 0.6675 val 0.6140 f1: 0.6021\n",
      "Epoch 1 loss: train 0.5952 val 0.5746 f1: 0.6961\n",
      "Epoch 2 loss: train 0.5567 val 0.5467 f1: 0.7613\n",
      "Epoch 3 loss: train 0.5378 val 0.5328 f1: 0.7523\n",
      "Epoch 4 loss: train 0.5203 val 0.5194 f1: 0.7633\n",
      "Epoch 5 loss: train 0.5011 val 0.5059 f1: 0.7631\n",
      "Epoch 6 loss: train 0.4995 val 0.5404 f1: 0.7855\n",
      "Epoch 7 loss: train 0.4898 val 0.5007 f1: 0.7922\n",
      "Epoch 8 loss: train 0.4642 val 0.4801 f1: 0.7885\n",
      "Epoch 9 loss: train 0.4613 val 0.4717 f1: 0.8054\n",
      "Epoch 10 loss: train 0.4642 val 0.5206 f1: 0.7925\n",
      "Epoch 11 loss: train 0.4636 val 0.4815 f1: 0.8022\n",
      "Epoch 12 loss: train 0.4284 val 0.4581 f1: 0.8146\n",
      "Epoch 13 loss: train 0.4681 val 0.5306 f1: 0.7850\n",
      "Epoch 14 loss: train 0.4839 val 0.4804 f1: 0.8038\n",
      "Epoch 15 loss: train 0.4590 val 0.4789 f1: 0.7650\n",
      "Epoch 16 loss: train 0.4249 val 0.4663 f1: 0.8118\n",
      "Epoch 17 loss: train 0.4081 val 0.4480 f1: 0.8191\n",
      "Epoch 18 loss: train 0.4035 val 0.4591 f1: 0.7868\n",
      "Epoch 19 loss: train 0.4130 val 0.4410 f1: 0.8166\n",
      "Epoch 20 loss: train 0.4403 val 0.4630 f1: 0.7881\n",
      "Epoch 21 loss: train 0.4334 val 0.4588 f1: 0.8177\n",
      "Epoch 22 loss: train 0.4169 val 0.5007 f1: 0.8011\n",
      "Epoch 23 loss: train 0.3945 val 0.4561 f1: 0.8179\n",
      "Epoch 24 loss: train 0.4009 val 0.4983 f1: 0.7984\n",
      "Epoch 25 loss: train 0.3858 val 0.4521 f1: 0.8165\n",
      "Epoch 26 loss: train 0.3801 val 0.4925 f1: 0.8028\n",
      "Epoch 27 loss: train 0.4100 val 0.4865 f1: 0.8013\n",
      "Epoch 28 loss: train 0.3946 val 0.4901 f1: 0.8012\n",
      "Epoch 29 loss: train 0.3855 val 0.4357 f1: 0.8259\n",
      "Epoch 30 loss: train 0.3704 val 0.4388 f1: 0.8234\n",
      "Epoch 31 loss: train 0.3710 val 0.4247 f1: 0.8309\n",
      "Epoch 32 loss: train 0.3728 val 0.4893 f1: 0.8071\n",
      "Epoch 33 loss: train 0.4301 val 0.4871 f1: 0.7513\n",
      "Epoch 34 loss: train 0.4234 val 0.4539 f1: 0.7903\n",
      "Epoch 35 loss: train 0.4152 val 0.4267 f1: 0.8240\n",
      "Epoch 36 loss: train 0.3963 val 0.4332 f1: 0.8265\n",
      "Epoch 37 loss: train 0.3809 val 0.5106 f1: 0.8002\n",
      "Epoch 38 loss: train 0.3731 val 0.4436 f1: 0.8222\n",
      "Epoch 39 loss: train 0.3612 val 0.5129 f1: 0.8025\n",
      "Epoch 40 loss: train 0.3961 val 0.4523 f1: 0.7859\n",
      "Epoch 41 loss: train 0.4129 val 0.4638 f1: 0.7725\n",
      "Epoch 42 loss: train 0.4088 val 0.4818 f1: 0.7453\n",
      "Epoch 43 loss: train 0.4148 val 0.4705 f1: 0.7647\n",
      "Epoch 44 loss: train 0.4009 val 0.4665 f1: 0.7780\n",
      "Epoch 45 loss: train 0.3948 val 0.4454 f1: 0.7875\n",
      "Epoch 46 loss: train 0.3862 val 0.4380 f1: 0.7963\n",
      "Epoch 47 loss: train 0.3774 val 0.4260 f1: 0.8095\n",
      "Epoch 48 loss: train 0.3726 val 0.4158 f1: 0.8238\n",
      "Epoch 49 loss: train 0.3583 val 0.4547 f1: 0.8187\n",
      "Epoch 50 loss: train 0.3627 val 0.4150 f1: 0.8225\n",
      "Epoch 51 loss: train 0.3646 val 0.4753 f1: 0.8103\n",
      "Epoch 52 loss: train 0.3592 val 0.4130 f1: 0.8290\n",
      "Epoch 53 loss: train 0.3516 val 0.4573 f1: 0.8175\n",
      "Epoch 54 loss: train 0.3779 val 0.4573 f1: 0.7746\n",
      "Epoch 55 loss: train 0.3873 val 0.4307 f1: 0.8010\n",
      "Epoch 56 loss: train 0.3800 val 0.4174 f1: 0.8265\n",
      "Epoch 57 loss: train 0.3603 val 0.4581 f1: 0.8162\n",
      "Epoch 58 loss: train 0.3547 val 0.4099 f1: 0.8315\n",
      "Epoch 59 loss: train 0.3527 val 0.4629 f1: 0.8128\n",
      "Epoch 60 loss: train 0.3683 val 0.4421 f1: 0.7889\n",
      "Epoch 61 loss: train 0.3793 val 0.4236 f1: 0.8087\n",
      "Epoch 62 loss: train 0.3699 val 0.4171 f1: 0.8218\n",
      "Epoch 63 loss: train 0.3597 val 0.4288 f1: 0.8266\n",
      "Epoch 64 loss: train 0.3474 val 0.4166 f1: 0.8315\n",
      "Epoch 65 loss: train 0.3426 val 0.4419 f1: 0.8245\n",
      "Epoch 66 loss: train 0.3726 val 0.4431 f1: 0.7905\n",
      "Epoch 67 loss: train 0.3772 val 0.4213 f1: 0.8276\n",
      "Epoch 68 loss: train 0.3628 val 0.4762 f1: 0.8021\n",
      "Epoch 69 loss: train 0.3491 val 0.4569 f1: 0.8143\n",
      "Epoch 70 loss: train 0.3488 val 0.4877 f1: 0.8045\n",
      "Epoch 71 loss: train 0.3439 val 0.4502 f1: 0.8202\n",
      "Epoch 72 loss: train 0.3478 val 0.5459 f1: 0.7938\n",
      "Epoch 73 loss: train 0.3529 val 0.4579 f1: 0.8193\n",
      "Epoch 74 loss: train 0.3389 val 0.4869 f1: 0.8073\n",
      "Epoch 75 loss: train 0.3372 val 0.4117 f1: 0.8322\n",
      "Epoch 76 loss: train 0.3304 val 0.4216 f1: 0.8342\n",
      "Epoch 77 loss: train 0.3198 val 0.4651 f1: 0.8275\n",
      "Epoch 78 loss: train 0.3378 val 0.5221 f1: 0.8056\n",
      "Epoch 79 loss: train 0.3449 val 0.4012 f1: 0.8333\n",
      "Epoch 80 loss: train 0.3423 val 0.4553 f1: 0.8283\n",
      "Epoch 81 loss: train 0.3567 val 0.4060 f1: 0.8279\n",
      "Epoch 82 loss: train 0.3708 val 0.4375 f1: 0.8261\n",
      "Epoch 83 loss: train 0.3349 val 0.4180 f1: 0.8350\n",
      "Epoch 84 loss: train 0.3282 val 0.5716 f1: 0.7983\n",
      "Epoch 85 loss: train 0.3585 val 0.4029 f1: 0.8330\n",
      "Epoch 86 loss: train 0.3553 val 0.4582 f1: 0.8180\n",
      "Epoch 87 loss: train 0.3306 val 0.4634 f1: 0.8224\n",
      "Epoch 88 loss: train 0.3199 val 0.5012 f1: 0.8178\n",
      "Epoch 89 loss: train 0.3570 val 0.4041 f1: 0.8362\n",
      "Epoch 90 loss: train 0.3572 val 0.4898 f1: 0.8063\n",
      "Epoch 91 loss: train 0.3341 val 0.4397 f1: 0.8307\n",
      "Epoch 92 loss: train 0.3219 val 0.4275 f1: 0.8344\n",
      "Epoch 93 loss: train 0.3181 val 0.5312 f1: 0.8080\n",
      "Epoch 94 loss: train 0.3574 val 0.4293 f1: 0.8034\n",
      "Epoch 95 loss: train 0.3609 val 0.5396 f1: 0.8056\n",
      "Epoch 96 loss: train 0.3413 val 0.4174 f1: 0.8329\n",
      "Epoch 97 loss: train 0.3219 val 0.4835 f1: 0.8140\n",
      "Epoch 98 loss: train 0.3497 val 0.4324 f1: 0.8295\n",
      "Epoch 99 loss: train 0.3482 val 0.5210 f1: 0.7979\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_losses, val_losses, val_f1s = [], [], []\n",
    "    best_score = -1\n",
    "    for x, y in train_dl:\n",
    "        opt.zero_grad()\n",
    "        pred = nn_clf(x)\n",
    "        y = y.unsqueeze(1).float()\n",
    "        loss = loss_function(pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_losses.append(loss.detach())\n",
    "    lr_scheduler.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dl:\n",
    "            pred = nn_clf(x)\n",
    "            y = y.unsqueeze(1).float()\n",
    "            loss = loss_function(pred, y)\n",
    "            val_losses.append(loss.detach())\n",
    "            val_f1s.append(f1_score(y, pred > .5))\n",
    "    train_loss = torch.tensor(train_losses).mean()\n",
    "    val_loss = torch.tensor(val_losses).mean()\n",
    "    val_f1 = torch.tensor(val_f1s).mean()\n",
    "    if val_f1 > best_score:\n",
    "        best_score = val_f1\n",
    "        torch.save(nn_clf.state_dict(), save_path)\n",
    "    print(f'Epoch {epoch} loss: train {train_loss:.4f} val {val_loss:.4f} f1: {val_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8561753620140976 0.7315887315887316\n"
     ]
    }
   ],
   "source": [
    "nn_clf.load_state_dict(torch.load('avg_pm_mlp.pth'))\n",
    "nn_clf.train(False)\n",
    "with torch.no_grad():\n",
    "    pred = nn_clf(torch.tensor(x_test))\n",
    "    print(roc_auc_score(y_test, pred), f1_score(y_test, pred > .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def per_project_f1(mns, tgts, preds, projs):\n",
    "    m_true_scores = defaultdict(dict)\n",
    "    m_false_scores = defaultdict(lambda: defaultdict(list))\n",
    "    for mn, tgt, pred, proj in zip(mns, tgts, preds, projs):\n",
    "        if tgt:\n",
    "            m_true_scores[proj][mn] = pred\n",
    "        else:\n",
    "            m_false_scores[proj][mn].append(pred)\n",
    "    f1s = []\n",
    "    for proj in m_true_scores.keys():\n",
    "        tp, n_refs, n_methods = 0, 0, 0\n",
    "        for mn, mts in m_true_scores[proj].items():\n",
    "            if not m_false_scores[proj][mn]:\n",
    "                continue\n",
    "            if max(mts, *m_false_scores[proj][mn]) > .5:\n",
    "                n_refs += 1\n",
    "                if mts > max(m_false_scores[proj][mn]):\n",
    "                    tp += 1\n",
    "            n_methods += 1\n",
    "        precision = tp / n_refs\n",
    "        recall = tp / n_methods\n",
    "        f1s.append(2 * precision * recall / (precision + recall))\n",
    "    return np.mean(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_test = [name for (name, *_) in test_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496250459159477"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_project_f1(mn_test, y_test, pred, proj_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
